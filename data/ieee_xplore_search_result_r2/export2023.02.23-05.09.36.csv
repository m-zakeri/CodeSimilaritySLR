"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Clone Stability","N. Göde; J. Harder","Software Engineering Group, University of Bremen, Bremen, Germany; Software Engineering Group, University of Bremen, Bremen, Germany","2011 15th European Conference on Software Maintenance and Reengineering","5 Apr 2011","2011","","","65","74","Code clones are said to threaten the maintainability of a system -- especially when the system evolves and source code is changed. Whether clones truly increase maintenance effort can be analyzed by comparing the stability of cloned code to the stability of non-cloned code. A previous study found that cloned code is even more stable than non-cloned code and, thus, requiring less maintenance effort -- contrary to the frequently voiced assumption. In this paper, we describe our partial replication and extension of this study using a more detailed measurement and considering different parameters for clone detection. In general, we were able to validate the findings of the previous study. We furthermore explored possible reasons to gain a better understanding of the unintuitive results.","1534-5351","978-1-61284-259-2","10.1109/CSMR.2011.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5741247","code clones;clone stability;experimentation","Cloning;Stability analysis;Maintenance engineering;Size measurement;Detectors;History;Software maintenance","software maintenance","code clone stability;system maintainability;source code;clone detection","","47","","22","IEEE","5 Apr 2011","","","IEEE","IEEE Conferences"
"In Vivo Evaluation of Large-Scale IR-Based Traceability Recovery","M. Borg","Department of Computer Science, Lund University, Lund, Sweden","2011 15th European Conference on Software Maintenance and Reengineering","5 Apr 2011","2011","","","365","368","Modern large-scale software development is a complex undertaking and coordinating various processes is crucial to achieve efficiency. The alignment between requirements and test activities is one very important aspect. Production and maintenance of software result in an ever-increasing amount of information. To be able to work efficiently under such circumstances, navigation in all available data needs support. Maintaining traceability links between software artifacts is one approach to structure the information space and support this challenge. Many researchers have proposed traceability recovery by applying information retrieval (IR) methods, utilizing the fact that artifacts often have textual content in natural language. Case studies have showed promising results, but no large-scale in vivo evaluations have been made. Currently, there is a trend among our industrial partners to move to a specific new software engineering tool. Their aim is to collect different pieces of information in one system. Our ambition is to develop an IR-based traceability recovery plug-in to this tool. From this position, right in the middle of a real industrial setting, many interesting observations could be made. This would allow a unique evaluation of the usefulness of the IR-based approach.","1534-5351","978-1-61284-259-2","10.1109/CSMR.2011.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5741348","requirements-test alignment;traceability;information retrieval;empirical software engineering","Software engineering;Companies;Software;USA Councils;Documentation;Large scale integration;Interviews","information retrieval;natural language processing;software maintenance;software tools;system recovery","in vivo evaluation;information retrieval;traceability recovery;software development;software production;software maintenance;traceability link maintenance;software artifact;natural language;software engineering tool","","1","","23","IEEE","5 Apr 2011","","","IEEE","IEEE Conferences"
"Revealing Mistakes in Concern Mapping Tasks: An Experimental Evaluation","C. Nunes; A. Garcia; E. Figueiredo; C. Lucena","Informatics Department-Opus Research Group, Software Engineering Lab, PUC-Rio, Rio de Janeiro, Brazil; Informatics Department-Opus Research Group, Software Engineering Lab, PUC-Rio, Rio de Janeiro, Brazil; Computer Science Department, Federal University of Minas Gerais, Belo Horizonte, Brazil; Informatics Department-Opus Research Group, Software Engineering Lab, PUC-Rio, Rio de Janeiro, Brazil","2011 15th European Conference on Software Maintenance and Reengineering","5 Apr 2011","2011","","","101","110","Concern mapping is the activity of assigning a stakeholder's concern to its corresponding elements in the source code. This activity is primordial to guide software maintainers in several tasks, such as understanding and restructuring the implementation of existing concerns. Even though different techniques are emerging to facilitate the concern mapping process, they are still manual and error-prone according to recent studies. Existing work does not provide any guidance to developers to review and correct concern mappings. In this context, this paper presents the characterization and classification of eight concern mapping mistakes commonly made by developers. These mistakes were found to be associated with various properties of concerns and modules in the source code. The mistake categories were derived from actual mappings of 10 concerns in 12 versions of industry systems. In order to further evaluate to what extent these mistakes also occur in wider contexts, we ran two experiments where 26 subjects mapped 10 concerns in two systems. Our experimental results confirmed the mapping mistakes that often occur when developers need to interact with the source code.","1534-5351","978-1-61284-259-2","10.1109/CSMR.2011.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5741266","Concern Mapping;Mapping Mistakes;Experimental Evaluation","Cloning;Context;Software;Accuracy;Logistics;Industries;Manuals","software maintenance","concern mapping task;source code;software maintenance","","5","","32","IEEE","5 Apr 2011","","","IEEE","IEEE Conferences"
"Migrating PL/I Code to Java","H. Sneed","Testing Department, Anecon GmbH, Vienna, Austria","2011 15th European Conference on Software Maintenance and Reengineering","5 Apr 2011","2011","","","287","296","This paper reports on a project to migrate PL/I programs running on an IBM mainframe under Z-OS to Java. The key point is that the transformation of the Code to Java was fully automated using the PLI2Java code transformation tool. The paper describes how the PL/I code was first reengineered to raise the quality and to put it into a form from which it could be converted over to an object - oriented architecture. It then goes on to define the process used to translate the code into Java. No less than 8 steps are required to make the transformation using static singleton objects with string data attributes and methods based on locality of reference. The Java components produced are object-oriented and data independent. In the end the results of the transformation are summarized and conclusions drawn for future work.","1534-5351","978-1-61284-259-2","10.1109/CSMR.2011.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5741273","PL/I;code reengineering;code transformation;Java;object–oriented migration","Java;Databases;Arrays;Retirement;Hardware;Programming","Java;PL/1;software architecture","PL/I program;IBM mainframe;Z-OS;PLI2Java code transformation tool;object-oriented architecture;static singleton object;string data","","4","2","38","IEEE","5 Apr 2011","","","IEEE","IEEE Conferences"
"Assistance System for OCL Constraints Adaptation during Metamodel Evolution","K. Hassam; S. Sadou; V. L. Gloahec; R. Fleurquin","Valoria laboratory, UEB, Vannes, France; Valoria laboratory, UEB, Vannes, France; Alkante SAS, France; Valoria laboratory, UEB, Vannes, France","2011 15th European Conference on Software Maintenance and Reengineering","5 Apr 2011","2011","","","151","160","Metamodels evolve over time, as well as other artifacts. In most cases, this evolution is performed manually by stepwise adaptation. In most cases, metamodels are described using the MOF language. Often OCL constraints are added to metamodels in order to ensure consistency of their instances (models). However, during metamodel evolution these constraints are omitted or manually rewritten, which is time consuming and error prone. We propose a tool to help the designer to make a decision on the constraints attached to a metamodel during its evolution. Thus, the tool highlights the constraints that should disappear after evolution and makes suggestions for those which need adaptation to remain consistent. For the latter case, we formally describe how the OCL constraints have to be transformed to preserve their syntactical correctness. Our adaptation rules are defined using QVT which is the OMG standard language for specifying model-to-model transformations.","1534-5351","978-1-61284-259-2","10.1109/CSMR.2011.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5741271","Metamodel evolution;OCL constraints;stepwise Adaptation;QVT","Context;Unified modeling language;Adaptation model;Syntactics;Companies;Connectors;Laboratories","formal specification;software prototyping","assistance system;OCL constraints adaptation;metamodel evolution;MOF language;syntactical correctness;QVT;OMG standard language;model-to-model transformation","","11","","27","IEEE","5 Apr 2011","","","IEEE","IEEE Conferences"
"An Analysis and Survey of the Development of Mutation Testing","Y. Jia; M. Harman","Centre for Research on Evolution, Search and Testing CREST, King''s College, London, UK; Centre for Research on Evolution, Search and Testing CREST, King''s College, London, UK","IEEE Transactions on Software Engineering","29 Sep 2011","2011","37","5","649","678","Mutation Testing is a fault-based software testing technique that has been widely studied for over three decades. The literature on Mutation Testing has contributed a set of approaches, tools, developments, and empirical results. This paper provides a comprehensive analysis and survey of Mutation Testing. The paper also presents the results of several development trend analyses. These analyses provide evidence that Mutation Testing techniques and tools are reaching a state of maturity and applicability, while the topic of Mutation Testing itself is the subject of increasing interest.","1939-3520","","10.1109/TSE.2010.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487526","Mutation testing;survey.","Genetic mutations;Software testing;Fault detection;History;Books;Programming profession;Computer languages;Java;Educational institutions;Automata","fault diagnosis;program testing","mutation testing development;fault-based software testing technique;empirical results;comprehensive analysis;development trend analysis;mutation testing technique;mutation testing tool","","962","3","264","IEEE","17 Jun 2010","","","IEEE","IEEE Journals"
"Compiler-assisted data distribution for chip multiprocessors","Y. Li; R. Melhem; A. Abousamra; A. K. Jones","Department of ECE, University of Pittsburgh, Pittsburgh, PA; Department of CS, University of Pittsburgh, Pittsburgh, PA; Department of CS, University of Pittsburgh, Pittsburgh, PA; Department of ECE, University of Pittsburgh, Pittsburgh, PA","2010 19th International Conference on Parallel Architectures and Compilation Techniques (PACT)","13 Feb 2017","2010","","","501","512","Data access latency, a limiting factor in the performance of chip multiprocessors, grows significantly with the number of cores in non-uniform cache architectures with distributed cache banks. To mitigate this effect, it is necessary to leverage the data access locality and choose an optimum data placement. Achieving this is especially challenging when other constraints such as cache capacity, coherence messages and runtime overhead need to be considered. This paper presents a compiler-based approach used for analyzing data access behavior in multi-threaded applications. The proposed experimental compiler framework employs novel compilation techniques to discover and represent multi-threaded memory access patterns (MMAPs). At run time, symbolic MMAPs are resolved and used by a partitioning algorithm to choose a partition of allocated memory blocks among the forked threads in the analyzed application. This partition is used to enforce data ownership by associating the data with the core that executes the thread owning the data. We demonstrate how this information can be used in an experimental architecture to accelerate applications. In particular, our compiler assisted approach shows a 20% speedup over shared caching and 5% speedup over the closest runtime approximation, “first touch”.","","978-1-4503-0178-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7851547","partitioning;data distribution;compiler-assisted caching","Distributed databases;Benchmark testing;Coherence;Runtime;Message systems;Organizations;Instruction sets","cache storage;data handling;microprocessor chips;multiprocessing systems;multi-threading;program compilers","compiler-assisted data distribution;chip multiprocessors;data access latency;limiting factor;nonuniform cache architectures;distributed cache banks;data access locality;optimum data placement;cache capacity;coherence messages;runtime overhead;data access behavior analysis;novel compilation techniques;multithreaded memory access patterns;symbolic MMAP;partitioning algorithm;allocated memory blocks partition;data ownership;closest runtime approximation;shared caching","","13","","24","","13 Feb 2017","","","IEEE","IEEE Conferences"
"Code clone detection in practice","F. Deissenboeck; B. Hummel; E. Juergens","Institut für Informatik, Technische Universität München, Garching bei Munchen, Germany; Institut für Informatik, Technische Universität München, Garching bei Munchen, Germany; Institut für Informatik, Technische Universität München, Garching bei Munchen, Germany","2010 ACM/IEEE 32nd International Conference on Software Engineering","27 Oct 2011","2010","2","","499","500","Due to the negative impact of code cloning on software maintenance efforts as well as on program correctness [4-6], the duplication of code is generally viewed as problematic. However, the techniques and tools developed by the research community in the last decade have not found broad acceptance in software engineering practice yet. This tutorial contributes to a more widespread application of existing approaches by illustrating where cloning comes from, what its consequences are, and how it can be detected.","1558-1225","978-1-60558-719-6","10.1145/1810295.1810449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062267","clone detection;redundancy","Cloning;Software;Tutorials;Software engineering;Communities;Redundancy;Manifolds","reproduction (copying);software maintenance","code duplication;software engineering;code clone detection;software maintenance","","6","","6","","27 Oct 2011","","","IEEE","IEEE Conferences"
"Fourth International Workshop on Software Clones (IWSC)","K. Inoue; S. Jarzabek; J. R. Cordy; R. Koshke","Osaka University, Japan; National University of Singapore, Singapore; University of Bremen, Germany; Queens University, Canada","2010 ACM/IEEE 32nd International Conference on Software Engineering","27 Oct 2011","2010","2","","465","466","Software clones are identical or similar pieces of code. They are often the result of copy--and--paste activities as ad-hoc code reuse by programmers. Software clones research is of high relevance for the industry. Many researchers have reported high rates of code cloning in both industrial and open-source systems. In this workshop we will explore lines of research that evaluate code clone detection methods, reason about ways to remove clones, assess the effect of clones on maintainablity, track clones' evolution, and investigate the root causes of clones.","1558-1225","978-1-60558-719-6","10.1145/1810295.1810431","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062250","code clone detection;software clone;software maintenance","Cloning;Conferences;Software;Educational institutions;Software engineering;Biological system modeling;Software algorithms","","","","","","18","","27 Oct 2011","","","IEEE","IEEE Conferences"
"Detecting recurring and similar software vulnerabilities","N. H. Pham; T. T. Nguyen; H. A. Nguyen; X. Wang; A. T. Nguyen; T. N. Nguyen","Iowa State University, USA; Iowa State University, USA; Iowa State University, USA; Iowa State University, USA; Iowa State University, USA; Iowa State University, USA","2010 ACM/IEEE 32nd International Conference on Software Engineering","27 Oct 2011","2010","2","","227","230","New software security vulnerabilities are discovered on almost daily basis and it is vital to be able to identify and resolve them as early as possible. Fortunately, many software vulnerabilities are recurring or very similar, thus, one could effectively detect and fix a vulnerability in a system by consulting the similar vulnerabilities and fixes from other systems. In this paper, we propose, SecureSync, an automatic approach to detect and provide suggested resolutions for recurring software vulnerabilities on multiple systems sharing/using similar code or API libraries. The core of SecureSync includes a usage model and a mapping algorithm for matching vulnerable code across different systems, a model for the comparison of vulnerability reports, and a tracing technique from a report to corresponding source code. Our preliminary evaluation with case studies showed the potential usefulness of SecureSync.","1558-1225","978-1-60558-719-6","10.1145/1810295.1810336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062166","","Security;Software;Vectors;Databases;Libraries;Computational modeling;Protocols","safety-critical software","software security vulnerability;SecureSync approach;recurring software vulnerability;API library;application program interface;vulnerable code matching;mapping algorithm;tracing technique","","1","","8","","27 Oct 2011","","","IEEE","IEEE Conferences"
"Flexible architecture conformance assessment with ConQAT","F. Deissenboeck; L. Heinemann; B. Hummel; E. Juergens","Technische Universität München, Garching bei Munchen, Germany; Technische Universität München, Garching bei Munchen, Germany; Technische Universität München, Garching bei Munchen, Germany; Technische Universität München, Garching bei Munchen, Germany","2010 ACM/IEEE 32nd International Conference on Software Engineering","27 Oct 2011","2010","2","","247","250","The architecture of software systems is known to decay if no counter-measures are taken. In order to prevent this architectural erosion, the conformance of the actual system architecture to its intended architecture needs to be assessed and controlled; ideally in a continuous manner. To support this, we present the architecture conformance assessment capabilities of our quality analysis framework ConQAT. In contrast to other tools, ConQAT is not limited to the assessment of use-dependencies between software components. Its generic architectural model allows the assessment of various types of dependencies found between different kinds of artifacts. It thereby provides the necessary tool-support for flexible architecture conformance assessment in diverse contexts.","1558-1225","978-1-60558-719-6","10.1145/1810295.1810343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062171","","Computer architecture;Databases;Software systems;Cloning;Java;Companies","software architecture;software quality","flexible architecture conformance assessment;software system architecture;software component;ConQAT quality analysis framework","","6","","11","","27 Oct 2011","","","IEEE","IEEE Conferences"
"Can clone detection support quality assessments of requirements specifications?","E. Juergens; F. Deissenboeck; M. Feilkas; B. Hummel; B. Schaetz; S. Wagner; C. Domann; J. Streit","Technische Universität München, Munchen, Germany; Technische Universität München, Munchen, Germany; Technische Universität München, Munchen, Germany; Technische Universität München, Munchen, Germany; Technische Universität München, Munchen, Germany; Technische Universität München, Munchen, Germany; Itestra GmbH, Munchen, Germany; Itestra GmbH, Munchen, Germany","2010 ACM/IEEE 32nd International Conference on Software Engineering","27 Oct 2011","2010","2","","79","88","Due to their pivotal role in software engineering, considerable effort is spent on the quality assurance of software requirements specifications. As they are mainly described in natural language, relatively few means of automated quality assessment exist. However, we found that clone detection, a technique widely applied to source code, is promising to assess one important quality aspect in an automated way, namely redundancy that stems from copy & paste operations. This paper describes a large-scale case study that applied clone detection to 28 requirements specifications with a total of 8,667 pages. We report on the amount of redundancy found in real-world specifications, discuss its nature as well as its consequences and evaluate in how far existing code clone detection approaches can be applied to assess the quality of requirements specifications in practice.","1558-1225","978-1-60558-719-6","10.1145/1810295.1810308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062141","clone detection;redundancy;requirements specification","Cloning;Software;Redundancy;Inspection;Programming;Quality assessment","formal specification;software quality","clone detection;quality assessment;software engineering;quality assurance;software requirements specification;source code;redundancy;copy operation;paste operation","","13","","26","","27 Oct 2011","","","IEEE","IEEE Conferences"
"Domain-specific tailoring of code smells: an empirical study","Y. Guo; C. Seaman; N. Zazworka; F. Shull","Department of Information Systems, University of Maryland Baltimore County, Baltimore, MD, USA; Department of Information Systems, University of Maryland Baltimore County, Baltimore, MD, USA; Fraunhofer Center of Experimental Software Engineering, College Park, MD, USA; Fraunhofer Center of Experimental Software Engineering, College Park, MD, USA","2010 ACM/IEEE 32nd International Conference on Software Engineering","27 Oct 2011","2010","2","","167","170","Code smells refer to commonly occurring patterns in source code that indicate poor programming practices or code decay. Detecting code smells helps developers find design problems that can cause trouble in future maintenance. Detection rules for code smells, based on software metrics, have been proposed, but they do not take domain-specific characteristics into consideration. In this study we investigate whether such generic heuristics can be tailored to include domain-specific factors. Input into these domain-specific heuristics comes from an iterative empirical field study in a software maintenance project. The results yield valuable insight into code smell detection.","1558-1225","978-1-60558-719-6","10.1145/1810295.1810321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062151","code smells;domain-specific;empirical study","Software;Measurement;Programming;Graphical user interfaces;Encoding;Couplings;Semantics","software maintenance;software metrics","domain-specific tailoring;code smells;source code;poor programming practices;code decay;software metrics;domain-specific heuristics;software maintenance project","","8","","6","","27 Oct 2011","","","IEEE","IEEE Conferences"
"Staying afloat in an expanding sea of choices: emerging best practices for eclipse rich client platform development","A. Kornstaedt; E. Reiswich","C1-WPS, Hamburg, Germany; C1-WPS, Hamburg, Germany","2010 ACM/IEEE 32nd International Conference on Software Engineering","27 Oct 2011","2010","2","","59","67","The Eclipse Rich Client Platform attracts considerable attention for being a promising candidate for providing the component model Java never had. This is even truer since the incorporation of OSGi for providing services within the framework. However, the rapid sequence of new versions and the continuous growth of features lead to a discussion that almost exclusively focused on technological aspects while leaving application developers in the midst of a sea of sometimes conflicting choices of how to implement their business-oriented applications. This lack of guidance leads to systems with vastly different architectures (or lack thereof) which often force complete rewrites when further development steps are to be taken. The best practices and architectural blueprints that provide this guidance in the field of object- or service-orientation haven't emerged yet. In this experience report, we render our observations made in several projects over the last years about the challenges that cooperating teams of application developers face when using RCP. We provide a first business-oriented architectural blue-print and best practices that have helped us greatly to overcome these challenges.","1558-1225","978-1-60558-719-6","10.1145/1810295.1810305","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062139","Eclipse;OSGi;RCP;bundles;component-based architecture;plug-in;rich client platform","Best practices;Libraries;Servers;Java;Software;Switches","object-oriented languages;software engineering","Eclipse rich client platform development;component model;Java;OSGi;business-oriented applications;architectural blueprints;object-orientation;service-orientation;RCP;business-oriented architectural blue-print","","","","27","","27 Oct 2011","","","IEEE","IEEE Conferences"
"Identifying crosscutting concerns using historical code changes","B. Adams; Z. M. Jiang; A. E. Hassan","Software Analysis and Intelligence Laboratory (SAIL), School of Computing, Queens University, Canada; Software Analysis and Intelligence Laboratory (SAIL), School of Computing, Queens University, Canada; Software Analysis and Intelligence Laboratory (SAIL), School of Computing, Queens University, Canada","2010 ACM/IEEE 32nd International Conference on Software Engineering","27 Oct 2011","2010","1","","305","314","Detailed knowledge about implemented concerns in the source code is crucial for the cost-effective maintenance and successful evolution of large systems. Concern mining techniques can automatically suggest sets of related code fragments that likely contribute to the implementation of a concern. However, developers must then spend considerable time understanding and expanding these concern seeds to obtain the full concern implementation. We propose a new mining technique (COMMIT) that reduces this manual effort. COMMIT addresses three major shortcomings of current concern mining techniques: 1) their inability to merge seeds with small variations, 2) their tendency to ignore important facets of concerns, and 3) their lack of information about the relations between seeds. A comparative case study on two large open source C systems (Post-greSQL and NetBSD) shows that COMMIT recovers up to 87.5% more unique concerns than two leading concern mining techniques, and that the three techniques complement each other.","1558-1225","978-1-60558-719-6","10.1145/1806799.1806846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062098","concern mining;empirical research;mining software repositories","Data mining;Mutual information;Scattering;Synchronization;Servers;Maintenance engineering;Software","C language;data mining;public domain software;software maintenance","crosscutting concerns;historical code;COMMIT;concern mining techniques;open source C systems;cost-effective maintenance","","16","","39","","27 Oct 2011","","","IEEE","IEEE Conferences"
"Recurring bug fixes in object-oriented programs","T. T. Nguyen; H. A. Nguyen; N. H. Pham; J. Al-Kofahi; T. N. Nguyen","Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA","2010 ACM/IEEE 32nd International Conference on Software Engineering","27 Oct 2011","2010","1","","315","324","Previous research confirms the existence of recurring bug fixes in software systems. Analyzing such fixes manually, we found that a large percentage of them occurs in code peers, the classes/methods having the similar roles in the systems, such as providing similar functions and/or participating in similar object interactions. Based on graph-based representation of object usages, we have developed several techniques to identify code peers, recognize recurring bug fixes, and recommend changes for code units from the bug fixes of their peers. The empirical evaluation on several open-source projects shows that our prototype, FixWizard, is able to identify recurring bug fixes and provide fixing recommendations with acceptable accuracy.","1558-1225","978-1-60558-719-6","10.1145/1806799.1806847","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062099","","Peer to peer computing;Object oriented modeling;Shape;Character recognition;Object oriented programming;Prototypes;Object recognition","graph theory;object-oriented programming;program debugging;public domain software","object-oriented programs;software systems;graph-based representation;open-source projects;recurring bug fixes","","28","","32","","27 Oct 2011","","","IEEE","IEEE Conferences"
"An analysis of the variability in forty preprocessor-based software product lines","J. Liebig; S. Apel; C. Lengauer; C. Kästner; M. Schulze","University of Passau, Germany; University of Passau, Germany; University of Passau, Germany; University of Magdeburg, Germany; University of Magdeburg, Germany","2010 ACM/IEEE 32nd International Conference on Software Engineering","27 Oct 2011","2010","1","","105","114","Over 30 years ago, the preprocessor cpp was developed to extend the programming language C by lightweight metaprogramming capabilities. Despite its error-proneness and low abstraction level, the preprocessor is still widely used in present-day software projects to implement variable software. However, not much is known about how cpp is employed to implement variability. To address this issue, we have analyzed forty open-source software projects written in C. Specifically, we answer the following questions: How does program size influence variability? How complex are extensions made via cpp's variability mechanisms? At which level of granularity are extensions applied? Which types of extension occur? These questions revive earlier discussions on program comprehension and refactoring in the context of the preprocessor. To provide answers, we introduce several metrics measuring the variability, complexity, granularity, and types of extension applied by preprocessor directives. Based on the collected data, we suggest alternative implementation techniques. Our data set is a rich source for rethinking language design and tool support.","1558-1225","978-1-60558-719-6","10.1145/1806799.1806819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062078","C preprocessor;empirical study;software product lines","Measurement;Software systems;Feature extraction;Complexity theory;Scattering;Correlation","C language;product development;program processors;software maintenance;software reusability","preprocessor-based software product lines;programming language C;present-day software projects;variability;open-source software projects;program comprehension;program refactoring;rethinking language design","","59","","35","","27 Oct 2011","","","IEEE","IEEE Conferences"
"Clone detection: Why, what and how?","M. Akhin; V. Itsykson","Saint Petersburg State Polytechnical University, Russia; Saint Petersburg State Polytechnical University, Russia","2010 6th Central and Eastern European Software Engineering Conference (CEE-SECR)","31 May 2011","2010","","","36","42","Excessive code duplication is a bane of modern software development. Several experimental studies show that on average 15 percent of a software system can contain source code clones - repeatedly reused fragments of similar code. While code duplication may increase the speed of initial software development, it undoubtedly leads to problems during software maintenance and support. That is why many developers agree that software clones should be detected and dealt with at every stage of software development life cycle. This paper is a brief survey of current state-of-the-art in clone detection. First, we highlight main sources of code cloning such as copy-and-paste programming, mental code patterns and performance optimizations. We discuss reasons behind the use of these techniques from the developer's point of view and possible alternatives to them. Second, we outline major negative effects that clones have on software development. The most serious drawback duplicated code have on software maintenance is increasing the cost of modifications - any modification that changes cloned code must be propagated to every clone instance in the program. Software clones may also create new software bugs when a programmer makes some mistakes during code copying and modification. Increase of source code size due to duplication leads to additional difficulty of code comprehension. Third, we review existing clone detection techniques. Classification based on used source code representation model is given in this work. We also describe and analyze some concrete examples of clone detection techniques highlighting main distinctive features and problems that are present in practical clone detection. Finally, we point out some open problems in the area of clone detection. Currently questions like ""What is a code clone?"", ""Can we predict the impact clones have on software quality"" and ""How can we increase both clone detection precision and recall at the same time? "" stay open to further research. We list the most important questions in modern clone detection and explain why they continue to remain unanswered despite all the progress in clone detection research.","","978-1-4577-0606-6","10.1109/CEE-SECR.2010.5783148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5783148","Clone detection;overview;program analysis;quality assurance;software maintenance","Cloning;Programming;Electronic mail;Software maintenance;Data mining;Linux","program debugging;software maintenance","clone detection techniques;code duplication;software development life cycle;software maintenance;software support;copy-and-paste programming;mental code patterns;performance optimizations;software bugs;source code size;code comprehension","","5","","","IEEE","31 May 2011","","","IEEE","IEEE Conferences"
"Code Similarities Beyond Copy & Paste","E. Juergens; F. Deissenboeck; B. Hummel","Institut für Informatik, Technische Universität München, Germany; Institut für Informatik, Technische Universität München, Germany; Institut für Informatik, Technische Universität München, Germany","2010 14th European Conference on Software Maintenance and Reengineering","17 Feb 2011","2010","","","78","87","Redundant source code hinders software maintenance, since updates have to be performed in multiple places. This holds independent of whether redundancy was created by copy&paste or by independent development of behaviorally similar code. Existing clone detection tools successfully discover syntactically similar redundant code. They thus work well for redundancy that has been created by copy&paste. But: how syntactically similar is behaviorally similar code of independent origin? This paper presents the results of a controlled experiment that demonstrates that behaviorally similar code of independent origin is highly unlikely to be syntactically similar. In fact, it is so syntactically different, that existing clone detection approaches cannot identify more than 1% of such redundancy. This is unfortunate, as manual inspections of open source software indicate that behaviorally similar code of independent origin does exist in practice and does present problems to maintenance.","1534-5351","978-0-7695-4321-5","10.1109/CSMR.2010.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714422","code similarity;open source","Cloning;Detectors;Manuals;Redundancy;Inspection;Java;Software maintenance","public domain software;software maintenance","code similarities;copy&paste;redundant source code;software maintenance;open source software","","29","","28","IEEE","17 Feb 2011","","","IEEE","IEEE Conferences"
"Designing Maintainable XML Transformations","S. Karus; M. Dumas","University Of Tartu, Estonia; University Of Tartu, Estonia","2010 14th European Conference on Software Maintenance and Reengineering","17 Feb 2011","2010","","","137","145","Modern applications often rely on XML to represent data internally and to interact with other applications and with end users. XSL transformations are commonly employed to transform between the internal representations of XML documents manipulated by an application and representations used for interaction with end-users and with other applications. These XSL transformations need to be updated whenever the underlying XML formats evolve. To address this maintenance problem, we formulate a number of guidelines for designing XSL transformations that are resilient to changes in the schema of the input XML documents. These guidelines are evaluated experimentally on the basis of three case studies. The evaluation shows that the use of these guidelines leads to more concise XSL transformations and to significant reductions in the amount of changes required to adapt existing XSL transformations in response to changes in the input schema.","1534-5351","978-0-7695-4321-5","10.1109/CSMR.2010.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714428","Software maintenance;forward compatibility;XML;XSL Transformations","Containers;Cities and towns;Europe;Navigation;HTML;Software maintenance","XML","XML transformations;end users;XML documents;XSL transformations","","1","","16","IEEE","17 Feb 2011","","","IEEE","IEEE Conferences"
"Vapor: Virtual Machine Based Parallel Program Profiling Framework","Y. Tan; W. Chen; Q. Wu","School of Computer, National University of Defense Technology, Changsha, Hunan, China; School of Computer, National University of Defense Technology, Changsha, Hunan, China; School of Computer, National University of Defense Technology, Changsha, Hunan, China","2010 IEEE 16th International Conference on Parallel and Distributed Systems","20 Jan 2011","2010","","","670","675","It is hard to execute parallel program efficiently on man-core platform because we could not divide program into appropriate granularity executed simultaneously. Based on virtual machine and binary translation technologies the article proposes the vapor profiling framework that uses SBIRP instruction in-place replacement method to collect program's run-time control flow and data flow information precisely. Moreover, it explains how to create control flow and data flow dependency graphs. Experiment results prove that vapor has better performance than traditional methods.","1521-9097","978-1-4244-9727-0","10.1109/ICPADS.2010.59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5695664","vapor;virtual machine;binary translation;program profiling","Virtual machining;Flow graphs;Virtual machine monitors;Operating systems;Monitoring;Context;Time factors","data flow computing;data flow graphs;parallel programming;virtual machines","virtual machine;parallel program profiling framework;man-core platform;binary translation technology;vapor profiling framework;super-block-based in-place replacement;instruction in-place replacement method;run-time control flow;data flow information;data flow dependency graph","","","","14","IEEE","20 Jan 2011","","","IEEE","IEEE Conferences"
"On Identifying Patterns in Code Repositories to Assist the Generation of Hardware Templates","A. Sanches; J. M. P. Cardoso","Faculdade de Engenharia Departamento de Engenharia Informática, Universidade do Porto, Porto, Portugal; Faculdade de Engenharia Departamento de Engenharia Informática, Universidade do Porto, Porto, Portugal","2010 International Conference on Field Programmable Logic and Applications","20 Jan 2011","2010","","","267","270","The identification of patterns on large repositories of code can be of paramount importance to guide the design of new hardware accelerators, to acquire the suitability of a certain hardware accelerator, and to generate application-specific architectures that maximize hardware reuse. This work intends to research and develop methods to both acquire the presence of a given pattern (map-suitability) and to identify common and highly similar patterns in code repositories (design-suggestions). The approach being proposed is based on a number of identification layers that refine the selections at each stage. We analyze two possible complementary options for a high-level layer. A first option is based on the representation of programs as a sequence of symbols and string matching and clustering algorithms are then used to expose similar patterns. A second option is based on tree matching techniques for identifying the presence of user's input patterns in the programs under inspection. We are evaluating our approach using the MiBench, MediaBench, UTDSP, and SNU code repositories. The results show the potential of our approach to identify approximate patterns that can be implemented by merging highly similar structures.","1946-1488","978-1-4244-7843-9","10.1109/FPL.2010.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694261","Hardware Patterns;Pattern-Mining;String Matching;Benchmarks;Reconfigurable Computing","Benchmark testing;Cloning;Hardware;Pattern matching;Arrays;Software;System-on-a-chip","pattern clustering;program testing;reconfigurable architectures;string matching;system-on-chip;trees (mathematics)","hardware templates generation;pattern identification;hardware accelerators;programs representation;symbols sequence;string matching;clustering algorithms;tree matching techniques;programs inspection;Media-Bench code repository;UTDSP code repository;SNU code repository;MiBench code repository","","6","","14","IEEE","20 Jan 2011","","","IEEE","IEEE Conferences"
"Rule-Based Composition Behaviors in Dynamic Plug-In Systems","M. Jahn; M. Loberbauer; R. Wolfinger; H. Mössenböck","Christian Doppler Laboratory for Automated Software Engineering, Johannes Kepler University Linz, Linz, Austria; Christian Doppler Laboratory for Automated Software Engineering, Johannes Kepler University Linz, Linz, Austria; Christian Doppler Laboratory for Automated Software Engineering, Johannes Kepler University Linz, Linz, Austria; Christian Doppler Laboratory for Automated Software Engineering, Johannes Kepler University Linz, Linz, Austria","2010 Asia Pacific Software Engineering Conference","20 Jan 2011","2010","","","80","89","Plug-in frameworks facilitate the development of customizable and extensible software, yet they often lack support for flexible and dynamic (re)configuration. We have created Plux.NET, a novel plug-in framework for plug-and-play composition. In Plux, a composer replaces programmatic composition with automatic composition. Components just specify their requirements and provisions using metadata, and the composer assembles the components guided by that metadata. This paper introduces rule-based composition behaviors, which are a means for controlling the composition process declaratively. Behavior rules constrain the composer by preventing certain operations or by triggering new ones. They help to establish a rule conformant composition state. Thereby, Plux supports developers in declarative and rule-based composition in order to minimize programming effort.","1530-1362","978-1-4244-8831-5","10.1109/APSEC.2010.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693183","Component-based software;Plug-in architecture;Run-time adaptation;Software reuse;Rule-based system","Plugs;Containers;Process control;Runtime;Programming;XML;Software","knowledge based systems;meta data;network operating systems;object-oriented programming;software architecture;software reusability","rule based composition behavior;dynamic plug-in system;extensible software;dynamic reconfiguration;Plux.NET;plug and play composition;programmatic composition;automatic composition;metadata;composition process;rule conformant composition state","","4","","10","IEEE","20 Jan 2011","","","IEEE","IEEE Conferences"
"QED: Quick Error Detection tests for effective post-silicon validation","T. Hong; Y. Li; S. -B. Park; D. Mui; D. Lin; Z. A. Kaleq; N. Hakim; H. Naeimi; D. S. Gardner; S. Mitra","Dept. of EE; Dept. of EE; Intel Corporation, Santa Clara, CA, USA; Dept. of EE; Dept. of EE; Dept. of EE; Intel Corporation, Santa Clara, CA, USA; Intel Corporation, Santa Clara, CA, USA; Intel Corporation, Santa Clara, CA, USA; Dept. of CS Stanford University, Stanford, CA, USA","2010 IEEE International Test Conference","20 Jan 2011","2010","","","1","10","Long error detection latency, the time elapsed between the occurrence of an error caused by a bug and its manifestation as a system-level failure, is a major challenge in post-silicon validation of robust systems. In this paper, we present a new technique called Quick Error Detection (QED), which transforms existing post-silicon validation tests into new validation tests that significantly reduce error detection latency. QED transformations allow flexible tradeoffs between error detection latency, coverage, and complexity, and can be implemented in software with little or no hardware changes. Results obtained from hardware experiments on quad-core Intel® Core™ i7 hardware platforms and from simulations on a multi-core MIPS processor design demonstrate that: 1. QED significantly improves error detection latencies by six orders of magnitude, i.e., from billions of cycles to a few thousand cycles or less. 2. QED transformations do not degrade the coverage of validation tests as estimated empirically by measuring the maximum operating frequencies over a wide range of operating voltage points. 3. QED tests improve coverage by detecting errors that escape the original non-QED tests.","2378-2250","978-1-4244-7207-9","10.1109/TEST.2010.5699215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5699215","","Program processors;Hardware","error detection;integrated circuit testing","quick error detection tests;effective post-silicon validation;error detection latency reduction;QED transformations;error detection latency;hardware experiments;quad-core Intel Core i7 hardware platforms;multicore MIPS processor design;QED transformation;QED test","","63","2","55","IEEE","20 Jan 2011","","","IEEE","IEEE Conferences"
"A comparative study on software vulnerability static analysis techniques and tools","Peng Li; Baojiang Cui","Institute of Electricity and Information Engineering, Beijing Institute of Civil Engineering and Architecture, Beijing, China; Institute of Computer, Beijing University of Posts and Telecommunications, Beijing, China","2010 IEEE International Conference on Information Theory and Information Security","17 Jan 2011","2010","","","521","524","Using static analysis tools can detect software vulnerabilities, which is important for improving the security of software. Static analysis technology has developed rapidly, but the comparison and evaluation of static analysis techniques and tools are not much. This paper focuses on software vulnerability static analysis techniques and tools. First we discuss the commonly-used static analysis techniques and tools, and compare these tools in a technical perspective, and then we analyze the characteristics of these tools through the experiment, finally, combining dynamic analysis, we propose an efficient software vulnerability detection method.","","978-1-4244-6943-7","10.1109/ICITIS.2010.5689543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5689543","Static Analysis;Software Security;Vulnerability;Static Analysis Tools","Software;Security;Java;Testing;Databases;Semantics;Analytical models","program diagnostics;security of data;software reliability;software tools","software vulnerability static analysis;static analysis tool;software security;dynamic analysis;software vulnerability detection","","10","1","9","IEEE","17 Jan 2011","","","IEEE","IEEE Conferences"
"Advances in DSP design tool flows for FPGAs","M. Jervis","DSP Tools, Altera Corporation, USA","2010 - MILCOM 2010 MILITARY COMMUNICATIONS CONFERENCE","6 Jan 2011","2010","","","2041","2046","This paper highlights recent advances in digital signal processing (DSP) design tools for Field-Programmable Gate Arrays (FPGAs), concentrating on model-based design high-level synthesis. Next generation FPGA model-based design tools provide a mechanism for abstracted design definition at the algorithmic rather than implementation level. The tools make use of FPGA structural and timing knowledge, and of mathematical and graph theory techniques to optimize and technology map the algorithm to a pipelined FPGA implementation, controlled by high level parameters and threshold settings. Such tools allow simple design space exploration and retargeting of algorithms to different device families. This design-once and retarget as required method improves productivity over manual hardware description language (HDL) coding, especially for projects which are subject to change. The simple design style, optimized generated hardware and productivity in design change and implementation exploration are highlighted with two examples; a direct radio-frequency (RF) radar design and a simple 8 by 8 beamforming design.","2155-7586","978-1-4244-8180-4","10.1109/MILCOM.2010.5680454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680454","","Field programmable gate arrays;Digital signal processing;Clocks;Pipeline processing;Hardware design languages;Radio frequency;Algorithm design and analysis","array signal processing;digital signal processing chips;field programmable gate arrays;graph theory","DSP design tool flow;digital signal processing design tool;model-based design high level synthesis;next generation FPGA;model-based design tool;graph theory;technology map;space exploration;hardware description language coding;direct radio frequency radar design;beamforming design;field programmable gate arrays","","3","","","IEEE","6 Jan 2011","","","IEEE","IEEE Conferences"
"Detect Related Bugs from Source Code Using Bug Information","D. Wang; M. Lin; H. Zhang; H. Hu","State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, Beihang University, Beijing, China","2010 IEEE 34th Annual Computer Software and Applications Conference","30 Dec 2010","2010","","","228","237","Open source projects often maintain open bug repositories during development and maintenance, and the reporters often point out straightly or implicitly the reasons why bugs occur when they submit them. The comments about a bug are very valuable for developers to locate and fix the bug. Meanwhile, it is very common in large software for programmers to override or overload some methods according to the same logic. If one method causes a bug, it is obvious that other overridden or overloaded methods maybe cause related or similar bugs. In this paper, we propose and implement a tool Rebug-Detector, which detects related bugs using bug information and code features. Firstly, it extracts bug features from bug information in bug repositories; secondly, it locates bug methods from source code, and then extracts code features of bug methods; thirdly, it calculates similarities between each overridden or overloaded method and bug methods; lastly, it determines which method maybe causes potential related or similar bugs. We evaluate Rebug-Detector on an open source project: Apache Lucene-Java. Our tool totally detects 61 related bugs, including 21 real bugs and 10 suspected bugs, and it costs us about 15.5 minutes. The results show that bug features and code features extracted by our tool are useful to find real bugs in existing projects.","0730-3157","978-1-4244-7513-1","10.1109/COMPSAC.2010.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5676263","bug information;common substring;bug features;code features;bug detection","Feature extraction;Computer bugs;Data mining;Software;Programming;Documentation;Java","Java;program debugging;public domain software;source coding","bug detection;source code;open source project;bug repository;Rebug- Detector;code features;bug information;Rebug-Detector;Apache Lucene-Java;bug features","","7","3","26","IEEE","30 Dec 2010","","","IEEE","IEEE Conferences"
"Re-Modularizing Traverse Feature from Various Perspectives in Software Reverse Engineering","Y. Su; W. -D. Zhong","Electronic Technology Dept, Engineering College of Armed Police Force, Xi'an, ShaanXi, China; Electronic Technology Dept, Engineering College of Armed Police Force, Xi'an, ShaanXi, China","2010 International Conference on Computational Intelligence and Software Engineering","30 Dec 2010","2010","","","1","4","To solve the identification and comprehension problem of crosscutting concerns in existing legacy software system, a framework of aspects-oriented software reverse engineering was proposed. An approach on re-modularizing traversal features of legacy system was presented, which based on various Unified Modeling Language (UML) diagrams. While modeling crosscutting concerns in UML use case diagrams, the non-functional requirements that affect several use case modules can be enveloped into aspects modules with stereotype mechanism. The recurring message transmission patterns can be re-modularized as aspects in UML sequence diagrams with UML collaborations. Standard UML activity diagram notations were extended and modified by nodes fusion and addition, which support the graphical composition operation between crosscutting behaviors and primary business rules of concurrent system. The case study indicates traversal features of software system can be extracted and re-modularized from various perspectives in aspects-oriented reverse engineering, which improves the comprehensibility and maintainability of legacy system.","","978-1-4244-5391-7","10.1109/CISE.2010.5676876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5676876","","Unified modeling language;Reverse engineering;Data mining;Software systems;Vehicles;Programming","reverse engineering;software maintenance;Unified Modeling Language","traverse feature remodularization;legacy software system;aspects-oriented software reverse engineering;unified modeling language diagrams;crosscutting concerns;message transmission patterns;standard UML activity diagram notations;nodes fusion;nodes addition;graphical composition operation;primary business rules;legacy system comprehensibility;legacy system maintainability","","","","7","IEEE","30 Dec 2010","","","IEEE","IEEE Conferences"
"Metric pictures: The approach and applications","R. Francese; S. Murad; I. Passero; G. Tortora","Dipartimento di Matematica e Informatica, University of Salerno, Italy; Dipartimento di Matematica e Informatica, University of Salerno, Italy; Dipartimento di Matematica e Informatica, University of Salerno, Italy; Dipartimento di Matematica e Informatica, University of Salerno, Italy","The 2010 International Conference on Computer Engineering & Systems","23 Dec 2010","2010","","","320","325","Source code metrics evaluate some aspects of software artefacts and provide synthetic measures of examined characteristics. Metrics are broadly adopted for code tracking, analysis and comprehension. In this paper, we present Metric Pictures, raster images obtained from source code metrics. With this method, the paper introduces algebra, derived from Image Elaboration, sounding with metric definitions. Metric Pictures with their operation set can be generally useful for underlining interesting features of analyzed code. As an example, the paper describes the application of the underlying logic and operators to Dead Code detection.","","978-1-4244-7042-6","10.1109/ICCES.2010.5674876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674876","Object oriented metrics;code comprehension;code analysis;metric visualization;image elaboration","Software;Visualization;Data visualization;Image color analysis;Software measurement;Algebra","algebra;software metrics","metric pictures;source code metrics;software artifacts;code tracking;algebra;image elaboration;dead code detection","","","","48","IEEE","23 Dec 2010","","","IEEE","IEEE Conferences"
"Using aspect oriented software architecture for enterprise systems development","P. K. Verma; D. Dahiya; P. Jain","Department of Computer Science, Jaypee University of Information Technology, Solan, Himachal Pradesh, India; Department of Computer Science, Jaypee University of Information Technology, Solan, Himachal Pradesh, India; Department of Computer Science, Jaypee University of Information Technology, Solan, Himachal Pradesh, India","2010 Fifth International Conference on Digital Information Management (ICDIM)","10 Dec 2010","2010","","","448","453","A typical software system comprises of several crosscutting concerns (also known as aspects). Code tangling and scattering are two difficulties that occur in current software implementation methodologies which affect software design and development in many ways like, poor traceability, lower productivity, less code reuse and poor code quality. Aspect Oriented Programming (AOP), which allows for modularizing of concerns that normally cause crosscutting in object oriented system, has efficiently solved the problem that the Object Oriented Programming has encountered such as the scattered codes and tangled codes resulting from the cross cutting concerns. Aspect-Oriented Software Development (AOSD) is becoming a new technique, which provides modularization of crosscutting concerns. The aim of this paper is to define an Aspect Oriented Software Architecture for software development with minimum code tangling and scattering. By this architecture not only the design efficiency can be improved but also the model built is easier to comprehend and reuse.","","978-1-4244-7573-5","10.1109/ICDIM.2010.5664715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5664715","Crosscutting;Aspect Oriented Programming;Object Oriented Programming;reuse;Java;AspectJ","Weaving;Programming;Software architecture;Computer architecture;Software;Scattering;Object oriented modeling","aspect-oriented programming;business data processing;Java;software architecture;software quality;software reusability","aspect oriented software architecture;enterprise system development;code tangling;code scattering;software design;code reuse;code quality;aspect oriented programming;concern modularization;object oriented system;object oriented programming;aspect-oriented software development;design efficiency;Java;AspectJ","","1","","20","IEEE","10 Dec 2010","","","IEEE","IEEE Conferences"
"Visualization of Multithreaded Behavior to Facilitate Maintenance of Complex Software Systems","J. Trümper; J. Bohnet; S. Voigt; J. Döllner","Hasso-Plattner-Institute - University of Potsdam, Germany; Hasso-Plattner-Institute - University of Potsdam, Germany; Hasso-Plattner-Institute - University of Potsdam, Germany; Hasso-Plattner-Institute - University of Potsdam, Germany","2010 Seventh International Conference on the Quality of Information and Communications Technology","3 Dec 2010","2010","","","325","330","Maintenance accounts for the major part of a software system's total costs. Therein, program comprehension is an important, but complex activity: Typically, up-to-date documentation is not available, so the main reliable source of information on the implementation represent the artifacts of the system's implementation. Understanding software systems is difficult, in particular, if multithreading concepts are involved because state-of-the art development tools provide only limited support for maintenance activities. In addition, concurrency is often not directly reflected by the source code, i.e., there is only a non-obvious correlation between control structures in the source code and a system's runtime behavior. We present a program comprehension technique that helps to analyze and understand runtime behavior of multithreaded software systems and, thereby, facilitates software maintenance tasks. Our approach contains the following concepts: First, light-weight dynamic analysis records executed method calls at runtime. Second, visualization of multithreading trace data allows developers to explore the system behavior post-mortem. The technique forms part of a scalable tool suite for understanding the behavior of complex software systems. We also show how to apply the technique on industrial software systems to solve common maintenance problems.","","978-1-4244-8539-0","10.1109/QUATIC.2010.59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5655671","multithreading;parallel computing;concurrency;threads;visualization;software;maintenance","Visualization;Instruction sets;Message systems;Runtime;Chromium;Software systems;Instruments","concurrency control;correlation methods;data visualisation;multi-threading;program control structures;software maintenance;system monitoring","complex software system maintenance;state of the art development tool;source code;system runtime behavior;program comprehension technique;multithreaded software system;dynamic analysis record executed method;industrial software system;control structure","","","","20","IEEE","3 Dec 2010","","","IEEE","IEEE Conferences"
"Exploratory Analysis of the Relations between Code Cloning and Open Source Software Quality","D. Kozlov; J. Koskinen; M. Sakkinen; J. Markkula","Department of Computer Science and Information Systems, University of Jyväskylä, Jyvaskyla, Finland; Department of Computer Science and Information Systems, University of Jyväskylä, Jyvaskyla, Finland; Department of Computer Science and Information Systems, University of Jyväskylä, Jyvaskyla, Finland; Department of Information Processing Science, University of Oulu, Oulu, Finland","2010 Seventh International Conference on the Quality of Information and Communications Technology","3 Dec 2010","2010","","","358","363","In recent literature there is still a lack of understanding how the reuse and cloning of software affects its quality. The focus of this study is to analyze the relationships between source code cloning and software quality for the case of open source software project forks (SPFs) as a kind of software reuse. In total 117 releases related to three generations of eight eMule SPFs were scrutinized. Software quality was measured in terms of internal quality attributes. The tools CCFinderX and SoftCalc were used to measure code cloning metrics and internal quality attributes, respectively. In total 8 code cloning metrics and 71 internal quality attributes were analyzed. The quantitative relationships between the code cloning metrics and internal quality attributes were identified based on Pearson product moment correlation analysis. Our results revealed a number of important relationships between the metrics under study.","","978-1-4244-8539-0","10.1109/QUATIC.2010.94","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5655665","software quality;internal quality attributes;code cloning;software reuse;open source software","Measurement;Cloning;Complexity theory;Software;Correlation;Heuristic algorithms;Arrays","public domain software;software management;software metrics;software quality;software reusability","exploratory analysis;open source software quality;software reuse;software cloning;source code cloning;software project forks;CCFinderX;SoftCalc;code cloning metrics","","5","","25","IEEE","3 Dec 2010","","","IEEE","IEEE Conferences"
"Studying the Effect of Refactorings: A Complexity Metrics Perspective","Q. D. Soetens; S. Demeyer","Department of Mathematics and Computer Sciences, University of Antwerp, Belgium; Department of Mathematics and Computer Sciences, University of Antwerp, Belgium","2010 Seventh International Conference on the Quality of Information and Communications Technology","3 Dec 2010","2010","","","313","318","Refactoring is widely recognized as a way to improve the internal structure of a software system in order to ensure its long-term maintainability. Consequently, software projects which adopt refactoring practices should see reductions in the complexity of their code base. We evaluated this assumption on an open source system-namely PMD, a Java source code analyzer-and discovered that periods of refactorings did not affect the cyclomatic complexity. This paper investigates this counterintuitive phenomenon through a detailed analysis of the actual source code manipulations applied on the system under study.","","978-1-4244-8539-0","10.1109/QUATIC.2010.58","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5655673","Refactoring;Complexity;Software Evolution;Maintenance;Mining Software Repositories","Complexity theory;Measurement;Software systems;Java;Mathematical analysis;Couplings","Java;public domain software;software maintenance;software management;software metrics;source coding","refactorings;complexity metrics perspective;internal structure;software system;long-term maintainability;software projects;open source system;Java source code analyzer;cyclomatic complexity","","13","","23","IEEE","3 Dec 2010","","","IEEE","IEEE Conferences"
"A Metrics-Based Approach to Technical Documentation Quality","A. Wingkvist; M. Ericsson; R. Lincke; W. Löwe","School of Computer Science, Linnaeus University, Sweden; Department of Information Technology, Uppsala University, Sweden; School of Computer Science, Linnaeus University, Sweden; School of Computer Science, Linnaeus University, Sweden","2010 Seventh International Conference on the Quality of Information and Communications Technology","3 Dec 2010","2010","","","476","481","Technical documentation is now fully taking the step from stale printed booklets (or electronic versions of these) to interactive and online versions. This provides opportunities to reconsider how we define and assess the quality of technical documentation. This paper suggests an approach based on the Goal-Question-Metric paradigm: predefined quality goals are continuously assessed and visualized by the use of metrics. To test this approach, we perform two experiments. We adopt well known software analysis techniques, e.g., clone detection and test coverage analysis, and assess the quality of two real world documentations, that of a mobile phone and of (parts of) a warship. The experiments show that quality issues can be identified and that the approach is promising.","","978-1-4244-8539-0","10.1109/QUATIC.2010.88","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5656407","Information quality;Quality assurance;Software metrics;Documentation","Documentation;Measurement;Cloning;Testing;Software quality;Mobile handsets","quality assurance;software metrics;software quality;system documentation","metrics-based approach;technical documentation quality;goal-question-metric paradigm;software analysis;clone detection;test coverage analysis;mobile phone;warship;software metrics;quality assurance;information quality","","13","","22","IEEE","3 Dec 2010","","","IEEE","IEEE Conferences"
"Collecting Quality Requirements Using Quality Models and Goals","R. Plösch; A. Mayr; C. Korner","Institute for Business Informatics-Software Engineering, Johannes Kepler University Linz, Linz, Austria; Institute for Business Informatics-Software Engineering, Johannes Kepler University Linz, Linz, Austria; Corporate Technology Siemens AG, Munich, Germany","2010 Seventh International Conference on the Quality of Information and Communications Technology","3 Dec 2010","2010","","","198","203","Determining the quality of a software product basically deals with checking the fulfillment of functional and quality requirements. Therefore, specifying useful and testable quality requirements is a central challenge. Many existing approaches focus on eliciting quality requirements, but often neglect the specification of respective test criteria. We present a bipartite approach that focuses on collecting testable quality requirements with quality models or goals as initial input. Firstly, using operational quality models enables us to derive measures in a goal-oriented approach that serve as basis for the specification of testable quality requirements. Secondly, identifying obstacles that obstruct goals helps closing gaps and enhances quality models. Our approach contributes to sharing and reusing common quality requirements by facilitating their specification based on a quality model. An initial application of our approach shows that it leads to quality requirements with clear criteria for testability. Nonetheless, the approach requires further applications in order to validate it in more detail and to identify improvement potentials.","","978-1-4244-8539-0","10.1109/QUATIC.2010.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5655265","quality requirement;quality model;goal;measure","Software;Software measurement;Libraries;Java;Unified modeling language;Biological system modeling;ISO standards","formal specification;object-oriented programming;program testing;software quality","quality models;software product quality;functional requirements;bipartite approach;testable quality requirements;goal-oriented approach","","3","","19","IEEE","3 Dec 2010","","","IEEE","IEEE Conferences"
"Improving the Design of Existing Web Applications","M. L. Bernardi; G. A. Di Lucca; D. Distante","Department of Engineering, University of Sannio, Italy; Department of Engineering, University of Sannio, Italy; Faculy of Economics, Unitelma Sapienza University, Italy","2010 Seventh International Conference on the Quality of Information and Communications Technology","3 Dec 2010","2010","","","499","504","Despite several methodologies have been defined to support the disciplined development of Web applications, often such methodologies are not applied in the practice, mainly due to the short time-to-market and resource constraints. As a consequence, existing (i.e. legacy) Web applications often lack in design quality. This paper proposes a model-driven semi-automatic redesign approach to improve the design of existing Web applications. The approach analyzes the client side HTML pages of the application to recover its conceptual model according to the Ubiquitous Web Applications design methodology. The recovered model is then used as a starting point to define a new design for the application, adopting the Model-View-Controller architectural pattern and the Java Server Faces technology. A concrete example of the application of the approach to redesign a real world Web site is also described.","","978-1-4244-8539-0","10.1109/QUATIC.2010.89","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5656403","Web Applications Quality Improvement;Web Application Redesign;Reverse Engineering;UWA","Navigation;Analytical models;Unified modeling language;Semantics;Publishing;HTML;Films","Java;software architecture;ubiquitous computing;Web design","design quality;model-driven semiautomatic redesign approach;client side HTML pages;ubiquitous Web applications design methodology;model-view-controller architectural pattern;Java server faces technology","","2","","17","IEEE","3 Dec 2010","","","IEEE","IEEE Conferences"
"Enhancing Source-Based Clone Detection Using Intermediate Representation","G. M. K. Selim; K. C. Foo; Y. Zou","School of Computing, Queen's University, Kingston, ONT, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ONT, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ONT, Canada","2010 17th Working Conference on Reverse Engineering","29 Nov 2010","2010","","","227","236","Detecting software clones in large scale projects helps improve the maintainability of large code bases. The source code representation (e.g., Java or C files) of a software system has traditionally been used for clone detection. In this paper, we propose a technique that transforms the source code to an intermediate representation, and then reuses established source-based clone detection techniques to detect clones in the intermediate representation. The clones are mapped back to the source code and are used to augment the results reported by source-based clone detection. We demonstrate the performance of our new technique using systems from the Bellon clone evaluation benchmark. The result shows that our technique can detect Type 3 clones. Our technique has higher recall with minimal drop in precision using Bellon corpus. By examining the complete clone groups, our technique has higher precision than the standalone string based and token based clone detectors.","2375-5369","978-1-4244-8911-4","10.1109/WCRE.2010.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645563","software clones;intermediate representation;token based clone detection tools;string based clone detection tools","Cloning;Java;Detectors;Merging;Benchmark testing;Encoding;Binary codes","program diagnostics;software maintenance","source based clone detection;software clone detection;software maintenance;large code base;source code representation;intermediate representation;Bellon clone evaluation benchmark;Bellon corpus","","23","","32","IEEE","29 Nov 2010","","","IEEE","IEEE Conferences"
"From Whence It Came: Detecting Source Code Clones by Analyzing Assembler","I. J. Davis; M. W. Godfrey","David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ONT, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ONT, Canada","2010 17th Working Conference on Reverse Engineering","29 Nov 2010","2010","","","242","246","To date, most clone detection techniques have concentrated on various forms of source code analysis, often by analyzing token streams. In this paper, we introduce a complementary technique of analyzing generated assembler for clones. This approach is appealing as it is mostly impervious to trivial changes in the source, with compilation serving as a kind of normalization technique. We have built detectors to analyze both Java VM code as well as GCC Linux assembler for C and C++. In the paper, we describe our approach and show how it can serve as a valuable complementary semantic approach to syntactic source code based detection.","2375-5369","978-1-4244-8911-4","10.1109/WCRE.2010.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645565","Clone Detection;Reverse Engineering","Cloning;Java;Software;Reverse engineering;Image edge detection;Syntactics;Arrays","C++ language;Java;Linux;program assemblers;program compilers;source coding","clone detection technique;source code analysis;assembler analysis;normalization technique;Java VM code;GCC Linux assembler;C;C++;syntactic source code based detection","","21","1","11","IEEE","29 Nov 2010","","","IEEE","IEEE Conferences"
"Highly Configurable and Extensible Code Clone Detection","B. Biegel; S. Diehl","University of Trier, Germany; University of Trier, Germany","2010 17th Working Conference on Reverse Engineering","29 Nov 2010","2010","","","237","241","Code clone detection is an enabling technology for plenty of applications, each having different requirements to a clone detector. In this paper we present a generic pipeline model of the code clone detection process. Based on this model we developed the JCCD code clone detection API for implementing custom clone detectors. By combining and parameterizing predefined API components as well as by adding new components, the pipeline model does not only facilitate to build new clone detectors, but also to parallelize the detection process.","2375-5369","978-1-4244-8911-4","10.1109/WCRE.2010.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645564","","Cloning;Pipelines;Detectors;Runtime;Software;Data preprocessing","application program interfaces;Java;pipeline processing","generic pipeline model;Java Code Clone Detection;API","","13","","16","IEEE","29 Nov 2010","","","IEEE","IEEE Conferences"
"Studying the Impact of Clones on Software Defects","G. M. K. Selim; L. Barbour; W. Shang; B. Adams; A. E. Hassan; Y. Zou","Queen's University, Kingston, Canada; Queen's University, Kingston, Canada; Queen's University, Kingston, Canada; Queen's University, Kingston, Canada; Queen's University, Kingston, Canada; Queen's University, Kingston, Canada","2010 17th Working Conference on Reverse Engineering","29 Nov 2010","2010","","","13","21","There are numerous studies that examine whether or not cloned code is harmful to software systems. Yet, few of them study which characteristics of cloned code in particular lead to software defects. In our work, we use survival analysis to understand the impact of clones on software defects and to determine the characteristics of cloned code that have the highest impact on software defects. Our survival models express the risk of defects in terms of basic predictors inherent to the code (e.g., LOC) and cloning predictors (e.g., number of clone siblings). We perform a case study using two clone detection tools on two large, long-lived systems using survival analysis. We determine that the defect-proneness of cloned methods is specific to the system under study and that more resources should be directed towards methods with a longer 'commit history'.","2375-5369","978-1-4244-8911-4","10.1109/WCRE.2010.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645480","","Cloning;Hazards;Predictive models;Data models;Software;Correlation;Mathematical model","software fault tolerance;statistical analysis","software defects;cloning predictors;clone detection tools;survival analysis","","41","","23","IEEE","29 Nov 2010","","","IEEE","IEEE Conferences"
"Understanding Feature Evolution in a Family of Product Variants","Y. Xue; Z. Xing; S. Jarzabek","School of Computing, National University of Singapore, Singapore; School of Computing, National University of Singapore, Singapore; School of Computing, National University of Singapore, Singapore","2010 17th Working Conference on Reverse Engineering","29 Nov 2010","2010","","","109","118","Existing software product variants, developed by ad hoc reuse such as copy-paste-modify, are often a starting point for building Software Product Line (SPL). Understanding of how features evolved in product variants is a prerequisite to transition from ad hoc to systematic SPL reuse. We propose a method that assists analysts in detecting changes to product features during evolution. We first entail that features and their inter-dependencies for each product variant are documented as product feature model. We then apply model differencing algorithm to identify evolutionary changes that occurred to features of different product variants. We evaluate the effectiveness of our approach on a family of medium-size financial systems. We also investigate the scalability of our approach with synthetic data. The evaluation demonstrates that our approach yields good results and scales to large systems. Our approach enables the subsequent variability analysis and consolidation of product variants in the task of reengineering product variants into SPL.","2375-5369","978-1-4244-8911-4","10.1109/WCRE.2010.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645450","","Feature extraction;Object oriented modeling;Unified modeling language;Merging;Analytical models;Authentication;Catalogs","software engineering","software product variants;software feature evolution;software product line;model differencing algorithm;medium-size financial systems;variability analysis","","10","","40","IEEE","29 Nov 2010","","","IEEE","IEEE Conferences"
"Computer-Aided Extraction of Software Components","A. Marx; F. Beck; S. Diehl","University of Trier, Germany; University of Trier, Germany; University of Trier, Germany","2010 17th Working Conference on Reverse Engineering","29 Nov 2010","2010","","","183","192","In a software project, outsourcing the development of a particular functionality, reusing a part in another software, or handing-over a part of the code to a new team member requires the extraction of an independent subset of the software-a component. This paper describes and analyzes the process of extracting such a component. We introduce an automated approach based on optimizing the cut between the new component and the remaining system. A visual development tool implements our approach and interactively supports the extraction. Finally, we look at the results of a thinking aloud user study and discuss the lessons learned about the extraction tool as well as the extraction process.","2375-5369","978-1-4244-8911-4","10.1109/WCRE.2010.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645558","","Contracts;Software;Production facilities;Java;Complexity theory;Data mining;Optimization","interactive systems;outsourcing;software management;software reusability","computer aided software component extraction;software development;software project","","8","","23","IEEE","29 Nov 2010","","","IEEE","IEEE Conferences"
"Extracting the similarity in detected software clones using metrics","A. Perumal; S. Kanmani; E. Kodhai","Department of CSE, SMVEC, Puducherry, India; Department of IT, PEC, Puducherry, India; Department of IT, SMVEC, Puducherry, India","2010 International Conference on Computer and Communication Technology (ICCCT)","18 Nov 2010","2010","","","575","579","Copying a code fragment and reusing it by pasting with or without minor modifications is a common practice in software development environments. Various techniques have been proposed to find duplicated redundant code. Previous work was simple and practical methods for detecting exact and near miss clones over arbitrary program fragments in program source code by using abstract syntax trees. Our proposal is a new technique for finding similar code blocks and for quantifying their similarity. Our techniques can be used to find clone clusters, sets of code blocks all within a user-supplied similarity. It detects similar clones using metrics for type 1, type 2 of clones.","","978-1-4244-9034-9","10.1109/ICCCT.2010.5640465","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5640465","Clone Detection;Software Clones;Software Metrics;Reuse","Cloning;Fingerprint recognition;Syntactics;Software systems;Measurement;Software maintenance","software metrics;software reusability","software clone detection;software metrics;code fragment;software development environment;duplicated redundant code;miss clone;arbitrary program fragment;program source code;abstract syntax trees;code block;clone cluster;user-supplied similarity;software reuse","","6","","34","IEEE","18 Nov 2010","","","IEEE","IEEE Conferences"
"An approach to graph mining using gSpan algorithm","S. Priyadarshini; D. Mishra","Department of Computer Applications and Department of Computer Science & Engineering, ITER, SOA University, Bhubaneswar, Orissa, India; Department of Computer Applications and Department of Computer Science & Engineering, ITER, SOA University, Bhubaneswar, Orissa, India","2010 International Conference on Computer and Communication Technology (ICCCT)","18 Nov 2010","2010","","","425","430","Complex information is prevailing in every sphere of activities This call for the necessity to represent, store and manipulate complex information (e.g. detects correlations and patterns, discover explanations, construct predictive models etc.). Furthermore, being autonomously maintained, data can change in time or even change its base structure, making it difficult for representation systems to accommodate these changes. Current representation and storage systems are not very flexible in dealing with big changes and also they are not concerned with the ability of performing complex data manipulations of the sort mentioned above. On the other hand, data manipulation systems cannot easily work with structural or relational data, but just with flat data representations. We want to bridge the gap between the two, by introducing a new type of database structure, called Graph Databases (GDB), based on a natural graph representation. Our Graph Databases are able to represent as graphs any kind of information, naturally accommodate changes in data, and they also make easier for Machine Learning methods to use the stored information. Graph mining is the process of extracting sub graphs from graph database or database of graphs. The problem of discovering frequent sub graphs of graph data can be solved by constructing a candidate set of sub graphs first, and then, identifying within this candidate set those sub graphs that meet the frequent sub graph requirement.","","978-1-4244-9034-9","10.1109/ICCCT.2010.5640496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5640496","Frequent sub graph;Label graph;Sub graph Isomorphism","Databases;Algorithm design and analysis;Data mining;Classification algorithms;Communications technology;Computers;Transforms","data mining;database management systems;learning (artificial intelligence)","graph mining;Gspan algorithm;data manipulation systems;graph database;machine learning methods","","","","9","IEEE","18 Nov 2010","","","IEEE","IEEE Conferences"
"Propagating Bug Fixes with Fast Subgraph Matching","B. Sun; G. Shu; A. Podgurski; S. Li; S. Zhang; J. Yang","Department of Electrical Engineering and Computer Science, Case Western Reserve University, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, USA","2010 IEEE 21st International Symposium on Software Reliability Engineering","11 Nov 2010","2010","","","21","30","We present a powerful and efficient approach to the problem of propagating a bug fix to all the locations in a code base to which it applies. Our approach represents bug and fix patterns as subgraphs of a system dependence graph, and it employs a fast, index-based subgraph matching algorithm to discover unfixed bug-pattern instances remaining in a code base. We have also developed a graphical tool to help programmers specify bug patterns and fix patterns easily. We evaluated our approach by applying it to bug fixes in four large open-source projects. The results indicate that the approach exhibits good recall and precision and excellent efficiency.","2332-6549","978-1-4244-9056-1","10.1109/ISSRE.2010.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635109","detection;program dependence graph;subgraph matching;graph indexing","Computer bugs;Pattern matching;Algorithm design and analysis;Labeling;Data structures;Indexing","graph theory;program debugging","bug fix propagation;subgraph matching algorithm;system dependence graph;graphical tool","","8","1","43","IEEE","11 Nov 2010","","","IEEE","IEEE Conferences"
"Application of RobustICA in the MIMO System","J. Zheng; R. Liu","Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing University of Posts and Telecommunications, Chongqing, China","2010 International Conference on Multimedia Technology","11 Nov 2010","2010","","","1","4","In this paper, we take advantage of the RobustICA which is the new achievement of Blind source separation. Committed to apply this method to MIMO communication system, approve the capacity of MIMO system by reducing the number of training sequence and the steps of channel estimation. The methods of this paper are all Semi-Blind, compared to the traditional method, new Semi-Blind scheme have advantage proved by simulation.","","978-1-4244-7874-3","10.1109/ICMULT.2010.5631123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5631123","","Robustness;MIMO;Phase shift keying;Source separation;Independent component analysis;Conferences;Information technology","blind source separation;channel estimation;independent component analysis;MIMO systems","RobustICA;MIMO system;blind source separation;MIMO communication system;training sequence;channel estimation;semi-blind","","","","16","IEEE","11 Nov 2010","","","IEEE","IEEE Conferences"
"One Fast Discrete Correlation Algorithm in the Frequency Domain","H. Cui; S. Gan; F. Han","College of Mechanical and Electrical Engineering, Inner Mongolia, Agricultural University, Hohhot, Inner Mongolia, China; College of Mechanical Engineering, Inner Mongolia University of Technology, Hohhot, Inner Mongolia, China; College of Mechanical Engineering, Inner Mongolia University of Technology, Hohhot, Inner Mongolia, China","2010 International Conference on Electrical and Control Engineering","11 Nov 2010","2010","","","1406","1409","Correlation algorithm in the frequency domain is now in widespread use due to Fast Fourier Transform Algorithm. However, its calculating speed and accuracy need to be further studied for the limited length sequence. A kind of discrete correlation algorithm in the frequency domain was derived based on analyzing the correlation theorem and vectors in the frequency domain. As is shown from the simulation experiments for two periodic signals and the composite signals of mixing the stochastic signal, the error of correlation values obtained by using the correlation algorithm in the frequency domain and the classic correlation algorithm in the time domain was lower than 10-6. Moreover, by contrast with the classic correlation algorithm in the time domain, the correlation algorithm in the frequency domain has higher accuracy and can enhance the calculation speed due to leave out the inverse FFT calculation step. It will play a significant role in removing the correlation components and solving the coherence components in composite signals.","","978-1-4244-6881-2","10.1109/iCECE.2010.348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5630878","Correlation algorithm in the time domain;Correlation algorithm in the frequency domain;FFT;signal identification;correlation error","Correlation;Frequency domain analysis;Time domain analysis;Algorithm design and analysis;Classification algorithms;Accuracy;Approximation algorithms","correlation theory;fast Fourier transforms","fast discrete correlation algorithm;frequency domain;fast Fourier transform algorithm;limited length sequence;periodic signal;composite signal;stochastic signal","","","","90","IEEE","11 Nov 2010","","","IEEE","IEEE Conferences"
"The Monitoring System for Electric Quantity Consumed in Extruder Based on WB Electrical Transducer","Z. Shuang; L. Fugang","College of Electric and Information Engineering, Heilongjiang Institute of Science and Technology, Harbin, China; College of Electric and Information Engineering, Heilongjiang Institute of Science and Technology, Harbin, China","2010 International Conference on Electrical and Control Engineering","11 Nov 2010","2010","","","4436","4438","A new system was discussed, which can be used to measure the performance parameters of extruders driven by asynchronous motor. By applying the WB electrical transducer and the electrical power method, the problem such as low-precision measurement is overcome. Match usage of C language, the system can display real-time parameters such as active power, rotational velocity, three-phase voltage and current on LCD. The system has a high performance price ratio and is good at transplant.","","978-1-4244-6881-2","10.1109/iCECE.2010.1079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5630883","electric quantity measurement;electrical transducer;extruder;asynchronous motor","Transducers;Current measurement;Power measurement;Converters;Energy measurement;Voltage measurement","agricultural machinery;C language;extrusion;induction motors;liquid crystal displays;power measurement;transducers","extruder;WB electrical transducer;asynchronous motor;electrical power method;C language;active power;rotational velocity;three-phase voltage;three-phase current;LCD;electric quantity measurement;electric quantity monitoring system","","","","28","IEEE","11 Nov 2010","","","IEEE","IEEE Conferences"
"VCAE: A Virtualization and Consolidation Analysis Engine for Large Scale Data Centers","H. Chen; H. Kang; G. Jiang; K. Yoshihira; A. Saxena","NEC Laboratories of America, Inc., Princeton, NJ, USA; SUNY at Stony Brook, Stony Brook, NY, USA; NEC Laboratories of America, Inc., Princeton, NJ, USA; NEC Laboratories of America, Inc., Princeton, NJ, USA; NEC Laboratories of America, Inc., Princeton, NJ, USA","2010 Fourth IEEE International Conference on Self-Adaptive and Self-Organizing Systems","11 Nov 2010","2010","","","1","10","Server consolidation through virtualization is becoming an effective way to save power and space in enterprise data centers. However, it also brings additional operational risks for the consolidated system because the impacts of hardware failures, human errors, and security breaches can be vastly magnified in that densely packed environment. In order to mitigate the above issues, this paper proposes a new virtualization and consolidation analysis engine(VCAE), which exploits and utilizes various constraints in the consolidation process. VCAE provides a comprehensive framework to discover, represent, check, and combine various constraints in server consolidation. It can assist system operators to effectively deal with the large number of constraints in the consolidation planning. In addition, VCAE proposes an evolution based method to discover the optimal consolidation scheme under multiple constraints. As a consequence, the consolidation solution generated by VCAE can not only maximize the utilization of system resources but also keep the hidden risks as low as possible in the consolidated system. The experimental results from an real enterprise system have demonstrated the advantages of our analysis engine.","1949-3681","978-1-4244-8537-6","10.1109/SASO.2010.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5630892","server consolidation;virtualization;constraints;optimization","Servers;Security;Maintenance engineering;Hardware;Resource management;Engines;Planning","business communication;computer centres;file servers;security of data;virtual machines","large scale data centers;server consolidation;enterprise data centers;hardware failures;human errors;security breaches;virtualization and consolidation analysis engine;system operators;consolidation planning;system resources;real enterprise system","","2","1","23","IEEE","11 Nov 2010","","","IEEE","IEEE Conferences"
"Distributed Control for Small Customer Energy Demand Management","V. V. Ranade; J. Beal","MIT CSAIL, Cambridge, MA, USA; BBN Technologies, GTE, Cambridge, MA, USA","2010 Fourth IEEE International Conference on Self-Adaptive and Self-Organizing Systems","11 Nov 2010","2010","","","11","20","We present the Colored Power algorithm, which is designed to provide collaborative electricity demand shaping for residential and small-business customers. Demand shaping for this market sector is an important and challenging problem, since the vast number of such customers collectively account for a large fraction of total electricity consumption, yet each individual's consumption is small. Under the PACEM system, customers participate by ""coloring"" their appliances with a qualitative priority such as ""can be shut off at peak power."" Demand shaping for this system must be scalable to millions of appliances, operate quickly and fairly across customers, and act on any given appliance infrequently. This last constraint is particularly challenging: if an appliance that switches on or off must not be switched again for many minutes, then at any instant, a large fraction of appliances may not be controllable. The Colored Power algorithm addresses these challenges using randomized local actions. When the action distribution is adjusted to compensate for currently uncontrollable appliances, standard feedback controllers can be used to produce local actions that combine to create the desired global effect. Experiments in simulation verify that the algorithm provides fair control that is fast, scalable, and robust enough to be realistically deployable.","1949-3681","978-1-4244-8537-6","10.1109/SASO.2010.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5630893","electricity demand management;demand shaping;peak-shaving;distributed algorithms;spatial computing;amorphous computing","Home appliances;Power demand;Probabilistic logic;Algorithm design and analysis;Robustness;Switches;Power measurement","demand side management;distributed control;energy management systems;feedback;power consumption;power markets;small-to-medium enterprises","distributed control;energy demand management;colored power algorithm;small-business customers;total electricity consumption;PACEM system;standard feedback controllers;demand shaping","","17","","13","IEEE","11 Nov 2010","","","IEEE","IEEE Conferences"
"A Model-Driven Architecture Approach to the Efficient Identification of Services on Service-Oriented Enterprise Architecture","S. Alahmari; D. d. Roure; E. Zaluska","School of Electronics and Computer Science University, Southampton, UK; School of Electronics and Computer Science University, Southampton, UK; School of Electronics and Computer Science University, Southampton, UK","2010 14th IEEE International Enterprise Distributed Object Computing Conference Workshops","11 Nov 2010","2010","","","165","172","Service-Oriented Enterprise Architecture requires the efficient development of loosely-coupled and interoperable sets of services. Existing design approaches do not always take full advantage of the value and importance of the engineering invested in existing legacy systems. This paper proposes an approach to define the key services from such legacy systems effectively. The approach focuses on identifying these services based on a Model-Driven Architecture approach supported by guidelines over a wide range of possible service types.","2325-6605","978-1-4244-7965-8","10.1109/EDOCW.2010.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5629010","SOEA;Service-Oriented Enterprise Architectures;Enterprise Engineering;Legacy systems;Architecture modelling;Model-Driven Architecture","Business;Unified modeling language;Object oriented modeling;Portfolios;Computer architecture;Analytical models;Measurement","software architecture;software maintenance","model-driven architecture approach;service-oriented enterprise architecture;legacy system","","3","","30","IEEE","11 Nov 2010","","","IEEE","IEEE Conferences"
"The effect of converter control method to characteristics of traction drive","R. Doleček; Z. Němec; O. Černý; J. Novák","Department of Software Engineering, University of Szeged Hungary; Department of Software Engineering, University of Szeged Hungary; USA Computer Science Department, College of William and Mary; Department of Software Engineering, University of Szeged Hungary","2010 12th Biennial Baltic Electronics Conference","11 Nov 2010","2010","","","285","288","The paper brings torque, power and efficiency analyses of the traction drive with permanent magnet synchronous motor (PMSM) during flux weakening operation. There is one way to weak flux of rotor permanent magnets - armature reaction caused by negative flux producing current component. On the other hand, the flux producing current component increases total RMS value of stator current. This effect has influence on losses and efficiency of PMSM. The paper investigates power, efficiency, torque and current characteristics in various operation points of PMSM drive.","2382-820X","978-1-4244-7356-4","10.1109/BEC.2010.5630880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5630880","","Traction motors;Torque;Stator windings;Converters;Permanent magnet motors;Resistance","permanent magnet motors;power convertors;synchronous motor drives;traction motor drives","converter control method;traction drive;permanent magnet synchronous motor;PMSM;rotor permanent magnets - armature reaction;RMS","","","","41","IEEE","11 Nov 2010","","","IEEE","IEEE Conferences"
"SOC design for wireless communications","Z. Stamenković","IHP Innovations for High Performance microelectronics, Frankfurt, Germany","2010 12th Biennial Baltic Electronics Conference","11 Nov 2010","2010","","","25","32","The paper emphasizes methods, architectures and components for system-on-chip design. It describes the basic knowledge and skills for designing high-performance low-power embedded devices whose complexity increases exponentially, as so does the effort of designing them. Relying upon an appropriate design methodology which concentrates on reuse, executable specifications, and early error detection, these complexities can be mastered. The paper bundles these topics in order to provide a good understanding of all problems involved. It shows how to go from description and verification to implementation and testing presenting two systems-on-chip for two different wireless applications based on configurable processors and custom hardware accelerators.","2382-820X","978-1-4244-7356-4","10.1109/BEC.2010.5630885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5630885","","Program processors;Hardware;Random access memory;System-on-a-chip;Generators;Wireless communication;Layout","error detection;low-power electronics;system-on-chip","SOC design;wireless communications;system-on-chip design;high-performance low-power embedded devices;executable specifications;error detection;configurable processors;hardware accelerators","","","","27","IEEE","11 Nov 2010","","","IEEE","IEEE Conferences"
"Web applications design evolution with UWA","M. L. Bernardi; M. Cimitile; D. Distante; F. Mazzone","RCOST-Department of Engineering, University of Sannio, Italy; Faculty of Economics, United ma Sapienza University, Italy; Faculty of Economics, United ma Sapienza University, Italy; RCOST-Department of Engineering, University of Sannio, Italy","2010 12th IEEE International Symposium on Web Systems Evolution (WSE)","9 Nov 2010","2010","","","3","12","This paper presents a semi-automatic approach to Web applications design evolution which leverages the Ubiquitous Web Applications (UWA) design framework, a methodology and a set of models and tools for the user-centered design of multi-channels and context-aware Web applications. The approach is based on a two-step redesign process: first a semi-automatic reverse modeling phase analyzes the html pages of the application front-end to abstract a model of the “as-is” design, according to the UWA formalism; second, a forward design phase starts from the recovered models and the (new) requirements available for the application to identify lacks and opportunities of improvements in the “as-is” design and produce the “to-be” version of it. The reverse modeling phase applies clustering and clone detection techniques and is supported by an Eclipse IDE environment. The forward design phase is supported by a set of UWA modeling tools which are built on top of the Eclipse Graphical Editing Framework (GEF) and of the Eclipse Graphical Modeling Framework (GMF) and that allow developers to evolve the recovered models. The results from a concrete case study to assess the validity of the redesign approach are also presented and discussed.","1550-4441","978-1-4244-8637-3","10.1109/WSE.2010.5623570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5623570","Web application redesign;Web systems evolution;UWA;clustering;clone detection;Eclipse;GEF;GMF","Analytical models;Navigation;HTML;Unified modeling language;Reverse engineering;Adaptation model;Context modeling","computer graphics;human computer interaction;hypermedia markup languages;pattern clustering;reverse engineering;ubiquitous computing;Web design","Web application design evolution;UWA;ubiquitous Web application;user-centered design;context-aware Web application;two-step redesign process;semiautomatic reverse modeling phase;html page;forward design phase;clustering technique;clone detection;eclipse IDE environment;eclipse graphical editing framework;eclipse graphical modeling framework","","4","","21","IEEE","9 Nov 2010","","","IEEE","IEEE Conferences"
"Understanding the aspects from various perspectives in aspects-oriented software reverse engineering","P. Zhang; Y. Su","Electronic Technology Dept., Engineering College of Armed Police Force, Xi'an, P.R.China; Electronic Technology Dept., Engineering College of Armed Police Force, Xi'an, P.R.China","2010 International Conference on Computer Application and System Modeling (ICCASM 2010)","4 Nov 2010","2010","11","","V11-311","V11-314","To solve the identification and comprehension problem of crosscutting concerns in existing legacy software system, a framework of aspects-oriented software reverse engineering was proposed. An approach on re-modularizing traversal features of legacy system was presented, which based on various Unified Modeling Language (UML) diagrams. While modeling crosscutting concerns in UML use case diagrams, the non-functional requirements that affect several use case modules can be enveloped into aspects modules with stereotype mechanism. The recurring message transmission patterns can be re-modularized as aspects in UML sequence diagrams with UML collaborations. Standard UML activity diagram notations were extended and modified by nodes fusion and addition, which support the graphical composition operation between crosscutting behaviors and primary business rules of concurrent system. The case study indicates traversal features of software system can be extracted and re-modularized from various perspectives in aspects-oriented reverse engineering, which improves the comprehensibility and maintainability of legacy system.","2161-9077","978-1-4244-7237-6","10.1109/ICCASM.2010.5623200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5623200","Crosscutting Concerns;Aspects Mining;Reverse Engineering;Aspect Oriented Programming (AOP);Unified Modeling Language (UML)","Unified modeling language;Reverse engineering;Data mining;Vehicles;Software systems;Programming","aspect-oriented programming;concurrency control;reverse engineering;software maintenance;Unified Modeling Language","aspects-oriented software reverse engineering;crosscutting concern;legacy software system;case diagrams;Unified Modeling Language sequence diagrams;UML collaborations;UML activity diagram notations;nodes fusion;graphical composition operation;concurrent system;legacy system comprehensibility;legacy system maintainability","","1","","6","IEEE","4 Nov 2010","","","IEEE","IEEE Conferences"
"The SQALE Analysis Model: An Analysis Model Compliant with the Representation Condition for Assessing the Quality of Software Source Code","J. -L. Letouzey; T. Coq","DNV IT Global Services, Arcueil, France; DNV IT Global Services, Arcueil, France","2010 Second International Conference on Advances in System Testing and Validation Lifecycle","1 Nov 2010","2010","","","43","48","This paper presents the analysis model of the assessment method of software source code SQALE (Software Quality Assessment Based on Lifecycle Expectations). We explain what brought us to develop consolidation rules based in remediation indices. We describe how the analysis model can be implemented in practice.","","978-1-4244-7784-5","10.1109/VALID.2010.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5617180","quality;source code;quality model;analysis model;SQAL","Software;Indexes;Analytical models;Aggregates;Software measurement;Object oriented modeling;Computational modeling","software quality","SQALE analysis model;analysis model compliant;assessment method;software source code SQALE;software quality assessment based on lifecycle expectation;consolidation rule;remediation index","","28","","10","IEEE","1 Nov 2010","","","IEEE","IEEE Conferences"
"Homology Detection Based on Abstract Syntax Tree Combined Simple Semantics Analysis","S. Wu; Y. Hao; X. Gao; B. Cui; C. Bian","China Information Technology Security Evaluation Center, Beijing, China; China Information Technology Security Evaluation Center, Beijing, China; China Information Technology Security Evaluation Center, Beijing, China; School of Computer Science and Technology, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science and Technology, Beijing University of Posts and Telecommunications, China","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","1 Nov 2010","2010","3","","410","414","Nowadays, the research of software homology detection is more and more important in the flourishing software market. Most of the existing detection tools are based on text structure but ignore the syntax framework structure of program codes. A few tools based on syntax structure do not consider detection on semantics level, which can be avoided by some plagiarism. The comparison system put forward in this paper combines comparison methods based on abstract syntax tree and simple semantics, such that being able to detect the homology software more accurately and comprehensively. It not only analyses the syntax structure of program codes, but also researches some simple semantics changes to achieve detection on both syntax and semantics level. Based on these, a homology detection system Code Compare is developed. Compared with other detection tools, Code Compare is capable of recognizing more code plagiarism types, thus can detect homology software more effectively.","","978-1-4244-8482-9","10.1109/WI-IAT.2010.100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5614410","homologous software;abstract syntax tree;simple semantics;CodeCompare","Syntactics;Semantics;Plagiarism;Cloning;Software;Algorithm design and analysis;Databases","computer crime;program diagnostics;programming language semantics","abstract syntax tree;semantics analysis;software market;program codes;software homology detection;code compare;code plagiarism","","1","","16","IEEE","1 Nov 2010","","","IEEE","IEEE Conferences"
"MAGISTER: Quality assurance of Magic applications for software developers and end users","C. Nagy; L. Vidács; R. Ferenc; T. Gyimóthy; F. Kocsis; I. Kovács","University of Szeged, Hungary; University of Szeged, Hungary; University of Szeged, Hungary; University of Szeged, Hungary; SZEGED Software Zrt., Hungary; SZEGED Software Zrt., Hungary","2010 IEEE International Conference on Software Maintenance","25 Oct 2010","2010","","","1","6","Nowadays there are many tools and methods available for source code quality assurance based on static analysis, but most of these tools focus on traditional software development techniques with 3GL languages. Besides procedural languages, 4GL programming languages such as Magic 4GL and Progress are widely used for application development. All these languages lie outside the main scope of analysis techniques. In this paper we present MAGISTER, which is a quality assurance framework for applications being developed in Magic, a 4GL application development solution created by Magic Software Enterprises. MAGISTER extracts data using static analysis methods from applications being developed in different versions of Magic (v5-9 and uniPaaS). The extracted data (including metrics, rule violations and dependency relations) is presented to the user via a GUI so it can be queried and visualized for further analysis. It helps software developers, architects and managers through the full development cycle by performing continuous code scans and measurements.","1063-6773","978-1-4244-8629-8","10.1109/ICSM.2010.5609550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5609550","Magic 4GL;Reverse Engineering;Quality Assurance;Metrics;Static Analysis","Measurement;Electronic mail;Encoding;Complexity theory;Software;Quality assurance","graphical user interfaces;program diagnostics;software quality","MAGISTER;quality assurance;Magic application;static analysis;4GL application development;v5-9;uniPaaS;GUI","","7","","8","IEEE","25 Oct 2010","","","IEEE","IEEE Conferences"
"Empirical software evolvability - code smells and human evaluations","M. V. Mäntylä","Department of Computer Science, Aalto University, Aalto, Finland","2010 IEEE International Conference on Software Maintenance","25 Oct 2010","2010","","","1","6","Low software evolvability may increase costs of software development for over 30%. In practice, human evaluations and discoveries of software evolvability dictate the actions taken to improve the software evolvability, but the human side has often been ignored in prior research. This dissertation synopsis proposes a new group of code smells called the solution approach, which is based on a study of 563 evolvability issues found in industrial and student code reviews. Solution approach issues require re-thinking of the existing implementation rather than just reorganizing the code through refactoring. This work also contributes to the body of knowledge about software quality assurance practices by confirming that 75% of defects found in code reviews affect software evolvability rather than functionality. We also found evidence indicating that context-specific demographics, i.e., role in organization and code ownership, affect evolvability evaluations, but general demographics, i.e., work experience and education, do not.","1063-6773","978-1-4244-8629-8","10.1109/ICSM.2010.5609545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5609545","Doctoral dissertation synopsis;code smells;empirical study;code review;human evaluation;software maintainability","Book reviews;Silicon;Software;Humans","program diagnostics;software performance evaluation;software prototyping;software quality","empirical software evolvability;code smells;human evaluations;software development;refactoring;software quality assurance","","2","","19","IEEE","25 Oct 2010","","","IEEE","IEEE Conferences"
"Automatic checking of license compliance","H. Zhang; Bei Shi; Lu Zhang","School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Peking University, Beijing, China","2010 IEEE International Conference on Software Maintenance","25 Oct 2010","2010","","","1","3","Open source software facilitates software reuse as developers can learn from code in existing open source projects. However, license compliance is an important legal issue that should be taken into consideration during open source based software reuse. Ignorance or carelessness could result in huge financial losses. In this paper, we present LChecker, a tool we developed for automatic checking of license compliance. LChecker utilizes Google Code Search service to check whether a local file exists in an OSS project and whether the licenses are compatible. The initial experimental results show that our tool is effective in detecting license compliance problems1.","1063-6773","978-1-4244-8629-8","10.1109/ICSM.2010.5609557","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5609557","license compliance;open source software;code search","","public domain software;software reusability","automatic checking;license compliance;open source software;software reuse;LChecker;Google code search service","","3","1","8","IEEE","25 Oct 2010","","","IEEE","IEEE Conferences"
"Using clone detection to identify bugs in concurrent software","K. Jalbert; J. S. Bradbury","Software Quality Research Group, Faculty of Science Computer Science, University of Ontario Institute of Technology (UOIT), Oshawa, ONT, Canada; Software Quality Research Group, Faculty of Science Computer Science, University of Ontario Institute of Technology (UOIT), Oshawa, ONT, Canada","2010 IEEE International Conference on Software Maintenance","25 Oct 2010","2010","","","1","5","In this paper we propose an active testing approach that uses clone detection and rule evaluation as the foundation for detecting bug patterns in concurrent software. If we can identify a bug pattern as being present then we can localize our testing effort to the exploration of interleavings relevant to the potential bug. Furthermore, if the potential bug is indeed a real bug, then targeting specific thread interleavings instead of examining all possible executions can increase the probability of the bug being detected sooner.","1063-6773","978-1-4244-8629-8","10.1109/ICSM.2010.5609529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5609529","active testing;bug patterns;clone detection;concurrency;fault localization;testing;static analysis","Computer bugs;Cloning;Concurrent computing;Testing;Pattern matching;Software;System recovery","concurrency control;program debugging;program testing","clone detection;concurrent software;active testing approach;rule evaluation;bug patterns detection","","2","1","15","IEEE","25 Oct 2010","","","IEEE","IEEE Conferences"
"A Tree Kernel based approach for clone detection","A. Corazza; S. Di Martino; V. Maggio; G. Scanniello","Dipartimento di Scienze Fisiche, Sezione Informatica University of Naples Federico II, Italy; Dipartimento di Scienze Fisiche, Sezione Informatica University of Naples Federico II, Italy; Dipartimento di Scienze Fisiche, Sezione Informatica University of Naples Federico II, Italy; Università della Basilicata, Potenza, Italy","2010 IEEE International Conference on Software Maintenance","25 Oct 2010","2010","","","1","5","Reusing software by copying and pasting is a common practice in software development. This phenomenon is widely known as code cloning. Problems with clones are mainly due to the need of managing each duplication, thus increasing the effort to maintain software systems. Clone detection approaches generally take into account either the syntactic structure (e.g., Abstract Syntax Tree) or lexical elements (e.g., the signature of a function). In this paper we propose an approach to detect code clones, based on syntactic information enriched by lexical elements. To this end, we have defined a Tree Kernel function to compare Abstract Syntax Trees. A preliminary investigation has been also conducted to assess the validity of the proposed approach.","1063-6773","978-1-4244-8629-8","10.1109/ICSM.2010.5609715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5609715","Clone Detection;Program Comprehension;Software Maintenance;Tree Kernels","Cloning;Kernel;Software systems;Syntactics;Java;Context","reverse engineering;software maintenance;software reusability","tree kernel function;clone detection;software reuse;software development;code cloning;software maintenance;syntactic structure;abstract syntax tree;lexical element;syntactic information;program comprehension","","13","","25","IEEE","25 Oct 2010","","","IEEE","IEEE Conferences"
"Index-based code clone detection: incremental, distributed, scalable","B. Hummel; E. Juergens; L. Heinemann; M. Conradt","Technische Universität München, Germany; Technische Universität München, Germany; Technische Universität München, Germany; Google Germany GmbH, Germany","2010 IEEE International Conference on Software Maintenance","25 Oct 2010","2010","","","1","9","Although numerous different clone detection approaches have been proposed to date, not a single one is both incremental and scalable to very large code bases. They thus cannot provide real-time cloning information for clone management of very large systems. We present a novel, index-based clone detection algorithm for type 1 and 2 clones that is both incremental and scalable. It enables a new generation of clone management tools that provide real-time cloning information for very large software. We report on several case studies that show both its suitability for real-time clone detection and its scalability: on 42 MLOC of Eclipse code, average time to retrieve all clones for a file was below 1 second; on 100 machines, detection of all clones in 73 MLOC was completed in 36 minutes.","1063-6773","978-1-4244-8629-8","10.1109/ICSM.2010.5609665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5609665","","Cloning;Indexes;Scalability;Software;Maintenance engineering;Real time systems;Detection algorithms","software maintenance","index-based code clone detection;clone management tool;42 MLOC;Eclipse code","","74","1","43","IEEE","25 Oct 2010","","","IEEE","IEEE Conferences"
"Template-based reconstruction of complex refactorings","K. Prete; N. Rachatasumrit; N. Sudan; M. Kim","Electrical and Computer Engineering, University of Texas, Austin, USA; Electrical and Computer Engineering, University of Texas, Austin, USA; Electrical and Computer Engineering, University of Texas, Austin, USA; Electrical and Computer Engineering, University of Texas, Austin, USA","2010 IEEE International Conference on Software Maintenance","25 Oct 2010","2010","","","1","10","Knowing which types of refactoring occurred between two program versions can help programmers better understand code changes. Our survey of refactoring identification techniques found that existing techniques cannot easily identify complex refactorings, such as an replace conditional with polymorphism refactoring, which consist of a set of atomic refactorings. This paper presents REF-FINDER that identifies complex refactorings between two program versions using a template-based refactoring reconstruction approach - REF-FINDER expresses each refactoring type in terms of template logic rules and uses a logic programming engine to infer concrete refactoring instances. It currently supports sixty three refactoring types from Fowler's catalog, showing the most comprehensive coverage among existing techniques. The evaluation using code examples from Fowler's catalog and open source project histories shows that REF-FINDER identifies refactorings with an overall precision of 0.79 and recall of 0.95.","1063-6773","978-1-4244-8629-8","10.1109/ICSM.2010.5609577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5609577","","Concrete;Databases;Catalogs;Cloning;Feature extraction;Software;Algorithm design and analysis","logic programming;software maintenance","complex refactorings;refactoring identification techniques;polymorphism refactoring;atomic refactorings;REF-FINDER;template-based refactoring reconstruction approach;template logic rules;logic programming engine;Fowler catalog","","118","","33","IEEE","25 Oct 2010","","","IEEE","IEEE Conferences"
"The network platform based on Struts2 + JPA + Spring framework","HaiLan Pan; Jian Chen; CuiHong Wu","School of Computer and Information, Shanghai Second Polytechnic University, Shanghai, China; School of Computer and Information, Shanghai Second Polytechnic University, Shanghai, China; School of Computer and Information, Shanghai Second Polytechnic University, Shanghai, China","2010 International Conference on Educational and Information Technology","25 Oct 2010","2010","1","","V1-69","V1-71","This paper discusses how to set up three-tier model based on lightweight framework Struts2, JPA and Spring in web application development. At first the article gives an example of some enterprise B2C website, and details site features and the architecture of the entire site, which uses Struts2 framework as the presentation layer, Spring framework as the control layer, JPA framework as the persistence layer to complete the Object-Relational Mapping (ORM) and related business logic. Then the paper describes the solution of several key technology involved the development process, and finally summaries advantages of this hierarchical model for developing web application, which can simplifying the development process, reuse logic code and so on.","","978-1-4244-8035-7","10.1109/ICEIT.2010.5607784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607784","business pattern;scalability;hierarchical model;International;E-commerce site","Rail to rail inputs;Browsers;Business;Databases","electronic commerce;Internet;object-oriented methods","Network Platform;Struts2 framework;three-tier model;web application development;B2C website;JPA framework;Spring framework;object relational mapping;ORM;business logic;internet","","1","","7","IEEE","25 Oct 2010","","","IEEE","IEEE Conferences"
"Modeling clones evolution in open source systems through chaos theory","D. M. Shawky; A. F. Ali","Engineering Mathematics Department Faculty of Engineering, Cairo University, Giza, Egypt; Biomedical Engineering Department, Faculty of Engineering, Helwan University, Helwan, Egypt","2010 2nd International Conference on Software Technology and Engineering","25 Oct 2010","2010","1","","V1-159","V1-164","A code clone is a code fragment that is identical or similar to another according to a certain similarity definition. Usually, it is a result of certain programmer's practices. Unjustified cloned codes can cause an increase in maintenance effort. In addition, they are -sometimes-a sign of poor design. This paper presents an approach for modeling clones evolution in open source systems. It adapts chaos theory for predicting clones in new versions of a software system. The number of clones in each version is identified and analyzed as a time series data. The existence of chaos is tested through the calculation of Lyapunov exponent and correlation dimension. Experimental results show that clones evolution in open source systems is a chaotic process. Thus, prediction in new versions can be done with high prediction accuracy using chaos theory.","","978-1-4244-8666-3","10.1109/ICSTE.2010.5608893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5608893","chaos theory;clones evolution;clones detection","Cloning;Chaos;Time series analysis;Correlation;Mutual information;Software;Delay","chaos;correlation methods;Lyapunov methods;public domain software;software engineering;source coding","modeling clones evolution;open source systems;chaos theory;code clone;code fragment;Lyapunov exponent;correlation dimension","","5","","36","IEEE","25 Oct 2010","","","IEEE","IEEE Conferences"
"Language-Independent Clone Detection Applied to Plagiarism Detection","R. Brixtel; M. Fontaine; B. Lesner; C. Bazin; R. Robbes","GREYC-CNRS UMR-6072, University of Caen Basse-Normandie, Caen, France; GREYC-CNRS UMR-6072, University of Caen Basse-Normandie, Caen, France; GREYC-CNRS UMR-6072, University of Caen Basse-Normandie, Caen, France; GREYC-CNRS UMR-6072, University of Caen Basse-Normandie, Caen, France; DCC, University of Chile, Santiago, Chile","2010 10th IEEE Working Conference on Source Code Analysis and Manipulation","14 Oct 2010","2010","","","77","86","Clone detection is usually applied in the context of detecting small-to medium scale fragments of duplicated code in large software systems. In this paper, we address the problem of clone detection applied to plagiarism detection in the context of source code assignments done by computer science students. Plagiarism detection comes with a distinct set of constraints to usual clone detection approaches, which influenced the design of the approach we present in this paper. For instance, the source code can be heavily changed at a superficial level (in an attempt to look genuine), yet be functionally very similar. Since assignments turned in by computer science students can be in a variety of languages, we work at the syntactic level and do not consider the source-code semantics. Consequently, the approach we propose is endogenous and makes no assumption about the programming language being analysed. It is based on an alignment method using the parallel principle at local resolution (character level) to compute similarities between documents. We tested our framework on hundreds of real source files, involving a wide array of programming languages (Java, C, Python, PHP, Haskell, bash). Our approach allowed us to discover previously undetected frauds, and to empirically evaluate its accuracy and robustness.","","978-1-4244-8655-7","10.1109/SCAM.2010.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601829","Endogenous;Plagiarism Detection;Similarity Measure;Distance;Source Code Segmentation;Source Code Plagiarism","Cloning;Plagiarism;Computer languages;Context;Robustness;Software systems","computer aided instruction;computer science education;programming languages;source coding","language independent clone detection;plagiarism detection;small-to medium scale fragments;computer science students;source code assignments;source code semantics;programming languages","","27","","24","IEEE","14 Oct 2010","","","IEEE","IEEE Conferences"
"Encapsulating Software Platform Logic by Aspect-Oriented Programming: A Case Study in Using Aspects for Language Portability","L. C. L. Kats; E. Visser","Software Engineering Research Group, Delft University of Technnology, Delft, Netherlands; Software Engineering Research Group, Delft University of Technnology, Delft, Netherlands","2010 10th IEEE Working Conference on Source Code Analysis and Manipulation","14 Oct 2010","2010","","","147","156","Software platforms such as the Java Virtual Machine or the CLR. NET virtual machine have their own ecosystem of a core programming language or instruction set, libraries, and developer community. Programming languages can target multiple software platforms to increase interoperability or to boost performance. Introducing a new compiler backend for a language is the first step towards targeting a new platform, translating the language to the platform's language or instruction set. Programs written in modern languages generally make extensive use of APIs, based on the runtime system of the software platform, introducing additional portability concerns. They may use APIs that are implemented by platform-specific libraries. Libraries may perform platform-specific operations, make direct native calls, or make assumptions about performance characteristics of operations or about the file system. This paper proposes to use aspect weaving to invasively adapt programs and libraries to address such portability concerns, and identifies four classes of aspects for this purpose. We evaluate this approach through a case study where we retarget the Stratego program transformation language towards the Java Virtual Machine.","","978-1-4244-8655-7","10.1109/SCAM.2010.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601821","programming languages;compilers;aspect-oriented programming;Stratego;Java;Spoofax","Libraries;Java;Software;Weaving;Runtime;Programming","application program interfaces;aspect-oriented programming;data encapsulation;instruction sets;Java;logic programming;program compilers;software libraries;software portability;virtual machines","software platform logic encapsulation;aspect-oriented programming;language portability;Java Virtual Machine;CLR. NET virtual machine;core programming language;instruction set;software library;developer community;interoperability;language compiler backend;API;runtime system;aspect weaving;program adaptation;Stratego program transformation language","","1","","23","IEEE","14 Oct 2010","","","IEEE","IEEE Conferences"
"New Conceptual Coupling and Cohesion Metrics for Object-Oriented Systems","B. Újházi; R. Ferenc; D. Poshyvanyk; T. Gyimóthy","Department of Software Engineering, University of Szeged, Hungary; Department of Software Engineering, University of Szeged, Hungary; Computer Science Department, The College of William and Mary, USA; Department of Software Engineering, University of Szeged, Hungary","2010 10th IEEE Working Conference on Source Code Analysis and Manipulation","14 Oct 2010","2010","","","33","42","The paper presents two novel conceptual metrics for measuring coupling and cohesion in software systems. Our first metric, Conceptual Coupling between Object classes (CCBO), is based on the well-known CBO coupling metric, while the other metric, Conceptual Lack of Cohesion on Methods (CLCOM5), is based on the LCOM5 cohesion metric. One advantage of the proposed conceptual metrics is that they can be computed in a simpler (and in many cases, programming language independent) way as compared to some of the structural metrics. We empirically studied CCBO and CLCOM5 for predicting fault-proneness of classes in a large open source system and compared these metrics with a host of existing structural and conceptual metrics for the same task. As the result, we found that the proposed conceptual metrics, when used in conjunction, can predict bugs nearly as precisely as the 58 structural metrics available in the Columbus source code quality framework and can be effectively combined with these metrics to improve bug prediction.","","978-1-4244-8655-7","10.1109/SCAM.2010.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601833","","Couplings;Large scale integration;Software systems;Classification algorithms;Software measurement","object-oriented methods;program debugging;public domain software;software fault tolerance;software metrics","conceptual coupling;cohesion metrices;object oriented system;software metrics system;programming language;Columbus source code quality framework;bug prediction;open source system;fault proneness","","30","1","41","IEEE","14 Oct 2010","","","IEEE","IEEE Conferences"
"Estimating the Optimal Number of Latent Concepts in Source Code Analysis","S. Grant; J. R. Cordy","School of Computing, Queen's University, Kingston, ONT, Canada; School of Computing, Queen's University, Kingston, ONT, Canada","2010 10th IEEE Working Conference on Source Code Analysis and Manipulation","14 Oct 2010","2010","","","65","74","The optimal number of latent topics required to model the most accurate latent substructure for a source code corpus is an open question in source code analysis. Most estimates about the number of latent topics that exist in a software corpus are based on the assumption that the data is similar to natural language, but there is little empirical evidence to support this. In order to help determine the appropriate number of topics needed to accurately represent the source code, we generate a series of Latent Dirichlet Allocation models with varying topic counts. We use a heuristic to evaluate the ability of the model to identify related source code blocks, and demonstrate the consequences of choosing too few or too many latent topics.","","978-1-4244-8655-7","10.1109/SCAM.2010.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601828","concept location;source code analysis;latent dirichlet allocation;latent topic model","Biological system modeling;Cloning;Data models;Measurement;Natural languages;Semantics;Information retrieval","program diagnostics;statistical analysis","latent concepts;latent topics;source code corpus;source code analysis;software corpus;latent Dirichlet allocation models;source code blocks;latent substructure","","32","","28","IEEE","14 Oct 2010","","","IEEE","IEEE Conferences"
"Refactoring Support for Modularity Maintenance in Erlang","H. Li; S. Thompson","School of Computing, University of Kent, UK; School of Computing, University of Kent, UK","2010 10th IEEE Working Conference on Source Code Analysis and Manipulation","14 Oct 2010","2010","","","157","166","Low coupling between modules and high cohesion inside each module are key features of good software architecture. Systems written in modern programming languages generally start with some reasonably well-designed module structure, however with continuous feature additions, modifications and bug fixes, software modularity gradually deteriorates. So, there is a need for incremental improvements to modularity to avoid the situation when the structure of the system becomes too complex to maintain. We demonstrate how Wrangler, a general-purpose refactoring tool for Erlang, can be used to maintain and improve the modularity of programs written in Erlang without dramatically changing the existing module structure. We identify a set of ""modularity smells"", and show how they can be detected by Wrangler and removed by way of a variety of refactorings implemented in Wrangler. Validation of the approach and usefulness of the tool are demonstrated by case studies.","","978-1-4244-8655-7","10.1109/SCAM.2010.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601817","Modularity Maintenance;program analaysis;program transformation;refactoring;Erlang","Manganese;Programming;Computer languages;Software architecture;Software;Maintenance engineering;Application programming interface","software architecture;software maintenance","support refactoring;modularity maintenance;Erlang;software architecture;software modularity;Wrangler;general purpose refactoring tool","","2","","13","IEEE","14 Oct 2010","","","IEEE","IEEE Conferences"
"Why Source Code Analysis and Manipulation Will Always be Important","M. Harman","CREST Centre, Department of Computer Science, University of London, London, UK","2010 10th IEEE Working Conference on Source Code Analysis and Manipulation","14 Oct 2010","2010","","","7","19","This paper makes a case for Source Code Analysis and Manipulation. The paper argues that it will not only remain important, but that its importance will continue to grow. This argument is partly based on the 'law' of tendency to executability, which the paper introduces. The paper also makes a case for Source Code Analysis purely for the sake of analysis. Analysis for its own sake may not be merely indulgent introspection. The paper argues that it may ultimately prove to be hugely important as source code gradually gathers together all aspects of human socioeconomic and governmental processes and systems.","","978-1-4244-8655-7","10.1109/SCAM.2010.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601835","slicing;source code analysis;transformation","Computers;Humans;Engines;Automation;Complexity theory;Unified modeling language;Software","program diagnostics;source coding","source code analysis;source code manipulation;human socioeconomic processes;governmental processes","","31","","90","IEEE","14 Oct 2010","","","IEEE","IEEE Conferences"
"Evaluating Code Clone Genealogies at Release Level: An Empirical Study","R. K. Saha; M. Asaduzzaman; M. F. Zibran; C. K. Roy; K. A. Schneider","Department of Computer Science, University of Saskatchewan, Saskatoon, SAS, Canada; Department of Computer Science, University of Saskatchewan, Saskatoon, SAS, Canada; Department of Computer Science, University of Saskatchewan, Saskatoon, SAS, Canada; Department of Computer Science, University of Saskatchewan, Saskatoon, SAS, Canada; Department of Computer Science, University of Saskatchewan, Saskatoon, SAS, Canada","2010 10th IEEE Working Conference on Source Code Analysis and Manipulation","14 Oct 2010","2010","","","87","96","Code clone genealogies show how clone groups evolve with the evolution of the associated software system, and thus could provide important insights on the maintenance implications of clones. In this paper, we provide an in-depth empirical study for evaluating clone genealogies in evolving open source systems at the release level. We develop a clone genealogy extractor, examine 17 open source C, Java, C++ and C# systems of diverse varieties and study different dimensions of how clone groups evolve with the evolution of the software systems. Our study shows that majority of the clone groups of the clone genealogies either propagate without any syntactic changes or change consistently in the subsequent releases, and that many of the genealogies remain alive during the evolution. These findings seem to be consistent with the findings of a previous study that clones may not be as detrimental in software maintenance as believed to be (at least by many of us), and that instead of aggressively refactoring clones, we should possibly focus on tracking and managing clones during the evolution of software systems.","","978-1-4244-8655-7","10.1109/SCAM.2010.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601826","code clone;clone evolution;empirical study;open source software","Cloning;Java;History;Software systems;Programming","C++ language;program compilers;public domain software;software maintenance","code clone genealogy evaluation;software system evolution;open source systems;clone genealogy extractor;open source C;C++;C# systems;software maintenance","","31","","27","IEEE","14 Oct 2010","","","IEEE","IEEE Conferences"
"Gossamer: A Lightweight Approach to Using Multicore Machines","J. A. Roback; G. R. Andrews","Department of Computer Science, University of Arizona Tucson, Tucson, AZ, USA; Department of Computer Science, University of Arizona Tucson, Tucson, AZ, USA","2010 39th International Conference on Parallel Processing","11 Oct 2010","2010","","","30","39","The key to performance improvements in the multi-core era is for software to utilize the available concurrency. This paper presents a lightweight programming framework called Gossamer that is easy to use, enables the solution of a broad range of parallel programming problems, and produces efficient code. Gossamer contains (1) a set of high-level annotations that one adds to a sequential program to specify concurrency and synchronization, (2) a source-to-source translator that produces an optimized program that uses our threading library, and (3) a run-time system that provides efficient threads and synchronization. Gossamer supports iterative and recursive parallelism, pipelined computations, domain decomposition, and MapReduce computations.","2332-5690","978-1-4244-7913-9","10.1109/ICPP.2010.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5599222","gossamer;parallel;programming;languages;annotations;C","Concurrent computing;Synchronization;Parallel processing;Instruction sets;Arrays;Jacobian matrices;Programming","concurrency control;multiprocessing systems;parallel programming","Gossamer;multicore machines;lightweight programming framework;parallel programming;high-level annotations;sequential program;concurrency control;source-to-source translator;run-time system;iterative parallelism;recursive parallelism;pipelined computations;domain decomposition;MapReduce computations","","3","","27","IEEE","11 Oct 2010","","","IEEE","IEEE Conferences"
"A Study on Crosscutting Refactoring Using Progam Dependency Relation","S. -H. Lee; B. -H. Cho; Y. -J. Song","Department of Computer Engineering, Kyung Hee University, Yongin si, South Korea; Department of Computer Engineering, Kyung Hee University, Yongin si, South Korea; Department of Computer Engineering, Kyung Hee University, Yongin si, South Korea","2010 IEEE/ACIS 9th International Conference on Computer and Information Science","30 Sep 2010","2010","","","684","689","Refactoring is to make easier to read the code structure and upgrade maintenance without changing function of the system. Crosscutting refactoring defines an aspect as a specific part of the program and use materialized aspect specification. The purpose of this paper is to suggest a materialized approach for applying crosscutting concern to Object-oriented refactoring. First of all, duplicated code which is an important aspect of refactoring compares the nodes' order on the program dependency graph. And it converts to a backup of an aspect. Refactoring using this process can handle refactoring factor of the inside of the encapsulated object by a recombination of source code.","","978-1-4244-8198-9","10.1109/ICIS.2010.123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591019","Crosscutting Concern;Refactoring;Control Flow Graph;Program Dependency Graph","Indexes;Weaving;Programming;Flow graphs;Software;Computers;Process control","data encapsulation;graph theory;object-oriented programming;software maintenance;source coding","code structure;crosscutting;materialized approach;object-oriented refactoring;program dependency graph;source code;object encapsulation","","2","","11","IEEE","30 Sep 2010","","","IEEE","IEEE Conferences"
"WSIM: Detecting Clone Pages Based on 3-Levels of Similarity Clues","W. Jung; C. Wu; E. Lee","School of Computer Science and Engineering, Seoul National University, Seoul, South Korea; School of Computer Science and Engineering, Seoul National University, Seoul, South Korea; School of Computer Science and Engineering, Kyungpook National University, Daegu, South Korea","2010 IEEE/ACIS 9th International Conference on Computer and Information Science","30 Sep 2010","2010","","","702","707","Code clones often result in code inconsistencies, which eventually increase cost and degrade quality. Web applications have higher rate of clones than normal software and it is more and more necessary to detect clones in web applications. In this paper, three levels of views in detecting clone pairs are suggested for a web application. The proposed technique utilizes relationships between web pages, passed parameters, and target entities as similarity clues. The results of the experiments also represent the trade-off between recall rate and accuracy. And then, two approaches, static and dynamic selection, are suggested for deciding candidates of clone pairs. As a result, the combined strategy of three levels of methods and two approaches of candidate selection is recommended. Finally, applicability of the proposed approach is shown from the experiments.","","978-1-4244-8198-9","10.1109/ICIS.2010.102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591017","web application;page clone;similarity","Cloning;Accuracy;Web pages;Software;Visualization;Noise;Complexity theory","Internet","code clones;Web applications;target entities;clone page detection;similarity clue;web page;passed parameter;dynamic selection;static selection","","1","","16","IEEE","30 Sep 2010","","","IEEE","IEEE Conferences"
"Research on the Copy Detection Algorithm for Source Code Based on Program Organizational Structure Tree Matching","Q. Junping; S. Yongxi; S. Hongfeng","NA; NA; School of Information Engineering, Inner Mongolia University of Technology, Hohhot, China","2010 International Conference on E-Business and E-Government","30 Sep 2010","2010","","","4461","4464","Code plagiarism is an ubiquitous phenomenon in the teaching of Programming Language. A large number of source code can be automatically detected and uses the similarity value to determine whether the copy is present. It can greatly improve the efficiency of teachers and promote teaching quality. A algorithm is provided that firstly match program organizational structure tree and then process the methods of program to calculate the similarity value. It not only applies to process-oriented programming languages but also applies to object-oriented programming language.","","978-1-4244-6647-4","10.1109/ICEE.2010.1120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590938","Copy Detection for Source Code;Similarity;Organizational Structure Tree;Token String;Longest Common Subsequence","Educational institutions;Plagiarism;Computer languages;Software measurement;Cloning;Book reviews","computer science education;object-oriented languages;object-oriented programming;source coding;teacher training;ubiquitous computing","copy detection algorithm;source code;program organizational structure tree matching;ubiquitous phenomenon;programming language teaching;teaching quality;process-oriented programming languages;object-oriented programming language","","","","","IEEE","30 Sep 2010","","","IEEE","IEEE Conferences"
"Coping with abstraction in object orientation with a special focus on application errors","R. Rashkovits; I. Lavy","Management Information Systems Department, The Academic College of Emek Yisrael, Israel; Management Information Systems Department, The Academic College of Emek Yisrael, Israel","2010 5th International Conference on Computer Science & Education","30 Sep 2010","2010","","","277","287","In this study we present and discuss various solution strategies used by students concerning error-handling. Our data is based on accumulated instruction experience gained during several years of advanced OOP course with Java. Analysis the provided solutions according to a set of categories based on constructive principles concerning software programming and on a classification of abstraction levels concerning error handling. The obtained results reveals that majority of students have difficulties in utilizing the advanced error-handling mechanism offered by modern programming languages (i.e., exception mechanism). The students have also difficulties in exhibiting high level of abstraction concerning a proper design of exceptions' hierarchy.","","978-1-4244-6005-2","10.1109/ICCSE.2010.5593634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593634","Exception Handling;Object oriented design;Class hierarchy;level of abstraction","Java;Programming;Taxonomy;Valves;Runtime;Educational institutions","computer science education;educational courses;error handling;Java;object-oriented programming","object orientation;application error;instruction experience;advanced OOP course;Java;constructive principle;software programming;abstraction level;error handling;modern programming language;exception hierarchy;object-oriented design;exception handling","","","","22","IEEE","30 Sep 2010","","","IEEE","IEEE Conferences"
"Similarity detection in Java programming assignments","M. El Bachir Menai; N. S. Al-Hassoun","Department of Computer Science, CCIS, King Saud University, Riyadh, Saudi Arabia; Department of Computer Science, CCIS, King Saud University, Riyadh, Saudi Arabia","2010 5th International Conference on Computer Science & Education","30 Sep 2010","2010","","","356","361","Similarity detection tools are nowadays commonly used by instructors to prevent student cheating and to enforce academic integrity. Systems identifying similarity in programming assignments are generally classified as either attribute-based or structure-based systems. Attribute-based methods make statistical analysis of the program attributes to detect lexical changes. Whereas structure-based methods complete a deeper analysis of the program structure to detect hidden structural similarities. Both methods can be useful for student programming assignments which consist generally of small to medium size source codes. In this paper, we introduce a method that encompasses both approaches to fit characteristics of student Java programming assignments. Similarities between pairs of programs can be detected by either profiling their source codes and measuring their distance or parsing them and comparing their encodings using a method inspired by DNA sequencing. We describe our experimental prototype, called CAPlag (Computing Assignment Plagiarism), and illustrate the results of some exploratory experiments. We demonstrate that our method is able to accurately find similarities in Java programs by comparing our results against those obtained with JPlag, a Web based service, and show that our system can be useful for instructors to deal with different programming assignment cases.","","978-1-4244-6005-2","10.1109/ICCSE.2010.5593613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593613","Similarity detection;Programming assignment;Java;Attribute-based method;Structure-based method","Measurement;Plagiarism;Java;Programming profession;Layout","educational administrative data processing;Java;object-oriented programming;pattern classification;program compilers;source coding;statistical analysis;Web services","Java programming assignment;academic integrity;student cheating prevention;attribute based system;structure based system;statistical analysis;hidden structural similarity detection;source code;DNA sequencing;CAPlag;computing assignment plagiarism;Web based service","","19","","32","IEEE","30 Sep 2010","","","IEEE","IEEE Conferences"
"Assure High Quality Code Using Refactoring and Obfuscation Techniques","T. Long; L. Liu; Y. Yu; Z. Wan","School of Software, Tsinghua University, China; School of Software, Tsinghua University, China; Department of Computing, Open University, UK; School of Software, Tsinghua University, China","2010 Fifth International Conference on Frontier of Computer Science and Technology","16 Sep 2010","2010","","","246","252","Nowadays, software refactoring techniques are widely adopted to enhance the quality of software by improving its understandability, performance, as well as other quality related design attributes. On the other hand, various kinds of software obfuscation methods have been proposed to protect security-sensitive information involved in software implementations. This paper analyzes how refactoring and obfuscation use reverse transformations to improve quality and security of software code, and proposes a systematic modeling approach based on i* to support the selection of refactoring techniques and obfuscation methods under different social, environmental and operational situations. First, top-level softgoals guiding designer's decision making are identified and analyzed; next accidental programming “bad smells” and intentional code cracker's threats to these softgoals are identified and analyzed; then refactoring and obfuscation transformations are modeled as countermeasures for these threats; eventually their reversal relations and counteracting patterns are examined using example code segments.","2159-631X","978-1-4244-7779-1","10.1109/FCST.2010.85","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575758","Software Quality;i*;Refactoring;Obfuscation","Security;Software quality;Programming;Software systems;Usability;Systematics","software maintenance;software quality","software refactoring technique;software quality;software obfuscation method;software implementation;software code;systematic modeling","","2","","20","IEEE","16 Sep 2010","","","IEEE","IEEE Conferences"
"Aspect Mining Using Link Analysis","J. Huang; Y. Lu; J. Yang","Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China; Huazhong University of Science and Technology, Wuhan, China","2010 Fifth International Conference on Frontier of Computer Science and Technology","16 Sep 2010","2010","","","312","317","Aspect mining is a technique that decouples the crosscutting concerns from existing software systems. The goal of aspect mining is to refactor the existing software systems with Aspect Oriented Programming technology. Inspired by the link analysis of information retrieval technology, this paper describes a two-state model to approximate how crosscutting concerns can be discovered in the concern graphs extracted from programs. Our mining algorithm generates ”scatter” and ”centralization” of each program element for the final ranking. The convergency of the algorithm proves fast. The Ranking technique, considering both ”scatter” and ”centralization”, produces a final ranking for identifying crosscutting concerns. Our aspect mining approach is evaluated on numerous Java programs that are of the typical selections for aspect mining. Compared with existing aspect mining approaches, our mining approach captures more information that helps domain experts refactor software systems and prove effective in identifying crosscutting concerns.","2159-631X","978-1-4244-7779-1","10.1109/FCST.2010.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575927","","Mathematical model;Algorithm design and analysis;Data mining;Equations;Software systems;Computational modeling;Object oriented modeling","aspect-oriented programming;data mining","aspect mining;link analysis;software systems;aspect oriented programming technology;information retrieval technology;ranking technique;refactor software systems","","9","","23","IEEE","16 Sep 2010","","","IEEE","IEEE Conferences"
"Using Feedback Tags and Sentiment Analysis to Generate Sharable Learning Resources Investigating Automated Sentiment Analysis of Feedback Tags in a Programming Course","S. Cummins; L. Burd; A. Hatch","School of Engineering and Computing Sciences, Durham University, Durham, UK; School of Engineering and Computing Sciences, Durham University, Durham, UK; School of Engineering and Computing Sciences, Durham University, Durham, UK","2010 10th IEEE International Conference on Advanced Learning Technologies","16 Sep 2010","2010","","","653","657","This paper demonstrates how sentiment analysis can be used to identify differences in how students and staff perceive the opinions contained in feedback for programming work. The feedback considered in this paper is conceptually different in that it is given in the form of tags that when associated with a fragment of source code can be considered as a sharable learning resource. The research presented investigates the differences in perception of whether feedback is positive, negative or neutral according to students and examiners. This paper also investigates the adequacy of an automated sentiment analysis engine with a view that sentiment information when combined with the feedback tag and source code may create a more informative sharable learning resource. This paper describes the investigatory technique and presents the initial results. Results indicate that there are important differences between the sentiment of feedback perceived by students and examiners. This paper highlights the benefit of including sentiment data along with feedback.","2161-377X","978-1-4244-7145-4","10.1109/ICALT.2010.186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5572602","Sentiment Analysis;Feedback;Programming;Tagging","Humans;Programming profession;Education;Tag clouds;Book reviews","computer aided instruction;computer science education;educational courses;feedback;groupware","feedback tags;sentiment analysis;learning resources;investigatory technique;programming course","","4","","9","IEEE","16 Sep 2010","","","IEEE","IEEE Conferences"
"Understanding crosscutting concerns from various perspectives in software reverse engineering","Y. Su","Electronic Technology Dept., Engineering College of Armed Police Force, Xi‘an, ShaanXi, China","The 6th International Conference on Networked Computing and Advanced Information Management","16 Sep 2010","2010","","","145","150","To solve the identification and comprehension problem of crosscutting concerns in existing legacy software system, a framework of aspects-oriented software reverse engineering was proposed. An approach on re-modularizing traversal features of legacy system was presented, which based on various Unified Modeling Language (UML) diagrams. While modeling crosscutting concerns in UML use case diagrams, the non-functional requirements that affect several use case modules can be enveloped into aspects modules with stereotype mechanism. The recurring message transmission patterns can be re-modularized as aspects in UML sequence diagrams with UML collaborations. Standard UML activity diagram notations were extended and modified by nodes fusion and addition, which support the graphical composition operation between crosscutting behaviors and primary business rules of concurrent system. The case study indicates traversal features of software system can be extracted and re-modularized from various perspectives in aspects-oriented reverse engineering, which improves the comprehensibility and maintainability of legacy system.","","978-89-88678-26-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5572310","Crosscutting Concerns;Aspects Mining;Reverse Engineering;Aspect Oriented Programming (AOP);Unified Modeling Language (UML)","Collaboration;Vehicle dynamics","software engineering;Unified Modeling Language","software reverse engineering;unified modeling language;UML;stereotype mechanism;graphical composition operation;aspect oriented reverse engineering","","","","7","","16 Sep 2010","","","IEEE","IEEE Conferences"
"Design and implementation of log management module in three-dimensional spatial database management system","S. He; G. Liu; Z. He; Z. Weng","School of Computer Science and Technology, China University of Geoscience, Wuhan, China; School of Computer Science and Technology, China University of Geoscience, Wuhan, China; School of Computer Science and Technology, China University of Geoscience, Wuhan, China; School of Computer Science and Technology, China University of Geoscience, Wuhan, China","2010 18th International Conference on Geoinformatics","9 Sep 2010","2010","","","1","5","Log management module plays an important role in the massive spatial database management system. Recently there are few three-dimensional spatial database management systems with pertinent log management sub-system, or the administrator can only use the log, which is attached by database system, to recover the data. To improve this issue, hierarchical structure of the log management module should be taken into account. The overall design of three-dimensional spatial database management system is as follows: three-dimensional spatial database (including database system, file system), three-dimensional spatial data engine, and three-dimensional space management tools. The log management module is designed to solve the problem of complexity and inconvenience of three-dimensional spatial data manipulation records. According to the 3D spatial database management system design, we divided the log management into three layers. The log management system includes monitor layer of three-dimensional spatial database's triggers and file database system operations recording statements, interface layer of log management module of three-dimensional spatial database engine, and graphical user interface layer of log management module of three-dimensional spatial data management tools. Monitor layer design includes database system trigger design. When the database table has been dynamically created, the trigger will be automatically created and record the database operations, then the file system calls function to record the log. Interface layer design includes accessing the database, reading the log table in database and other integrated operations, including query and delete. Graphical user interface layer mainly includes the design of graphical interfaces, the function call form interface layer, and log data operations. In order to work on the layers conveniently, database system trigger and file database system's record are used to record the operation of the database. The log module interface in three-dimensional spatial data engine is used to exchange the data between graphical interface and underlying database. The log module in database management tools can directly provide a graphical interface, but not need to provide access functions to get the log data. This design method has an excellent scalability and flexibility, and can also be made appropriate changes to meet the new needs.","2161-0258","978-1-4244-7303-8","10.1109/GEOINFORMATICS.2010.5567648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567648","log management;graphical interface layer;interface layer;monitor layer;three-dimensional spatial database management system","Spatial databases;Database systems;Monitoring;Graphical user interfaces;Engines;Data models","data handling;visual databases","log management module;three-dimensional spatial database management system;hierarchical structure;data manipulation records;graphical user interface","","4","","5","IEEE","9 Sep 2010","","","IEEE","IEEE Conferences"
"Recognition on source codes similarity with weighted attributes eigenvector","S. Yang; X. Wang; C. Shao; P. Zhang","Faculty of Information and Electrical Engineering, Dalian University of Technology, Dalian, China; NA; NA; NA","2010 International Conference on Intelligent Control and Information Processing","9 Sep 2010","2010","","","539","543","The paper puts forward a new method to identify similar C codes based on weighted attributes eigenvector. According to the characteristics of physical and structure attributes of C codes, the weighing theory of attributes eigenvector is adopted to strengthen the infection of attribute elements with covert codes, which are based on the theory and method about existing kinds of attribute eigenvector in C codes. This can also improve the quality and veracity of the similarity recognition. Experiments show that the method can identify the integrated similarity with the three aspects of space characters, parameter variables and sentence sequences. Further more, comparing with ideal calculating results, the measure precision of integrated evaluation can reach to at least 94% in the cases of middle and high similarity.","","978-1-4244-7050-1","10.1109/ICICIP.2010.5565209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5565209","","Object recognition;Accuracy;Weight measurement;Current measurement;Particle measurements;Atmospheric measurements;Software","character recognition;eigenvalues and eigenfunctions;formal verification;source coding","source code similarity recognition;weighted attributes eigenvector;covert codes;space characters;parameter variables;sentence sequences;weighing theory","","1","","10","IEEE","9 Sep 2010","","","IEEE","IEEE Conferences"
"An approach for assessing similarity metrics used in metric-based clone detection techniques","D. M. Shawky; A. F. Ali","Engineering Mathematics Department Faculty of Engineering, Cairo University, Giza, Egypt; Biomedical Engineering Department Faculty of Engineering, Helwan University, Helwan, Egypt","2010 3rd International Conference on Computer Science and Information Technology","7 Sep 2010","2010","1","","580","584","Similarity is an important concept in information theory. A challenging question is how to measure the amount of shared information between two systems. A large number of metrics are proposed and used to measure similarity between two computer programs or two portions of the same program. In this paper, we present an approach for assessing which metrics are most useful for similarity prediction in the context of clone detection. The presented approach uses clustering to identify clone candidates. In the experiments conducted, we applied sequential clustering using all possible permutations of a subset of the metrics used in metric-based clone detection literature. Precision and recall are calculated in every experiment. Experimental results show that the order of the metrics used affects the results dramatically. This shows that the used metrics are of variable relevance.","","978-1-4244-5540-9","10.1109/ICCSIT.2010.5563834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563834","similarity metrics;clustering;clone detection","Measurement;Gold;Probabilistic logic;Cloning;Clustering algorithms","pattern clustering;software metrics","similarity metric assessment approach;information theory;metric-based clone detection techniques;similarity prediction techniques;sequential clustering;software metrics","","8","","35","IEEE","7 Sep 2010","","","IEEE","IEEE Conferences"
"The ‘deception’ of code smells: An empirical investigation","S. Counsell; H. Hamza; R. M. Hierons","School of Information Systems, Computing and Mathematics, Brunei University, Uxbridge, Middlesex, UK; School of Information Systems, Computing and Mathematics, Brunei University, Uxbridge, Middlesex, UK; School of Information Systems, Computing and Mathematics, Brunei University, Uxbridge, Middlesex, UK","Proceedings of the ITI 2010, 32nd International Conference on Information Technology Interfaces","12 Aug 2010","2010","","","683","688","Code smells represent code decay and as such should be eradicated from a system to prevent future maintenance problems. A range of twenty smells described by Fowler and Beck each require varying numbers and combinations of refactorings in order to be eradicated - but exactly how many are needed when we consider related, nested refactorings is unclear. In this paper, we enumerate these refactorings when categorised according to Mantyla's smell taxonomy. We then show how, ironically, the `smelliest' of smells (and hence most difficult to eradicate) are actually those best understood by developers. So, code smells are not only unpleasant to have around but are deceptive in their nature and make-up. The study is thus a warning against attempting what are seemingly easily eradicated smells - these are often the smells the developer needs to be most wary of.","1330-1012","978-1-4244-5733-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5546498","Refactoring;OO;Code smell","Taxonomy;Switches;Feature extraction;Couplings;Couplers;Surgery;Data mining","chemioception;codes;collections of physical data;testing","code smell;code decay;Mantyla smell taxonomy;maintenance problem;deception;testing","","","","16","","12 Aug 2010","","","IEEE","IEEE Conferences"
"An iterative, metric space based software clone detection approach","Z. Li; J. Sun","Computer Science College, University of Zhejiang, Hangzhou, China; Computer Science College, University of Zhejiang, Hangzhou, China","The 2nd International Conference on Software Engineering and Data Mining","9 Aug 2010","2010","","","111","116","Metric space is a set with definition of distance between elements within this set. This paper introduces metric space into code clone detection, and uses the distance within a metric space to measure the similarity level of code. It proposes an iterative process of building up a metric space to detect clones in software system. Based on metric space which is derived from software metric, the clone detection can avail us of more convenience and flexibility. We also exercise the approach in a real industry project.","","978-89-88678-22-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5542942","metric space;clone detection;software metric;iterative;proximity query (key words)","Iterative methods;Extraterrestrial measurements;Cloning;Software maintenance;Software systems;Computer science;Educational institutions;Software metrics;Logic;Sun","iterative methods;security of data;software metrics","software clone detection approach;metric space;code clone detection;iterative process;software system;software metric","","2","","","","9 Aug 2010","","","IEEE","IEEE Conferences"
"Taxonomy of static code analysis tools","J. Novak; A. Krajnc; R. Žontar","Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor; Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor; Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor","The 33rd International Convention MIPRO","29 Jul 2010","2010","","","418","422","Static code analysis tools are becoming more and more crucial in the software development lifecycle. In this paper we will present today most commonly used static code analysis tools. Because there are many types of these tools for many purposes and many programming languages we will try to classify them according to several categories like: technology, availability of rules, supported languages, extensibility and several other categories and subcategories. The purpose of this article is not to show which static code analysis tool is superior and which not, but to construct a taxonomy of static code analysis tools. After reading this article the reader will understand features and assets of the static code analysis tools.","","978-9-5323-3050-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5533417","","Taxonomy;Software tools;Computer languages;Testing;Pattern analysis;Computer science;Programming;Humans;Performance analysis;Software libraries","program verification;programming languages;software tools;source coding","taxonomy;static code analysis tools;software development lifecycle;programming languages","","1","","13","","29 Jul 2010","","","IEEE","IEEE Conferences"
"A Technique for Just-in-Time Clone Detection in Large Scale Systems","L. Barbour; H. Yuan; Y. Zou","Department of Electrical and Computer Engineering, Queen's University, Kingston, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, Canada","2010 IEEE 18th International Conference on Program Comprehension","26 Jul 2010","2010","","","76","79","Existing clone tracking tools have limited support for sharing clone information between developers in a large scale system. Developers are not notified when new clones are introduced by other developers or when existing clones are modified. We propose a client-server architecture that centrally detects and maintains clone information for an entire software system stored in a version control system. Clients retrieve a list of clones relevant to the code they are working on from the server. Whenever an update is committed to the version control system, the server detects and incrementally updates clone information. We propose techniques to improve the speed of the incremental clone detection. In order to reduce the number of comparisons required for clone detection, we select representative clones from the existing clone list. We build a string-based technique to compare the newly committed code with the representative clones and to update the clone list. In a case study, we show that our approach significantly reduces the clone detection time, while supporting clone detection across the entire software system.","1092-8138","978-1-4244-7603-9","10.1109/ICPC.2010.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5521760","","Cloning;Large-scale systems;Control systems;Software systems;Centralized control;Computer architecture;Software quality;Programming;Software maintenance;Detectors","client-server systems;software maintenance","just-in-time clone detection;large scale systems;client-server architecture;version control system;incremental clone detection;string-based technique","","5","1","17","IEEE","26 Jul 2010","","","IEEE","IEEE Conferences"
"Recognizing Sorting Algorithms with the C4.5 Decision Tree Classifier","A. Taherkhani","Department of Computer Science and Engineering, Aalto University of Science and Technology, Aalto, Finland","2010 IEEE 18th International Conference on Program Comprehension","26 Jul 2010","2010","","","72","75","We present a method for automatic algorithm recognition, which consists of two phases. First, the target algorithms are converted into characteristic vectors, which are computed based on static analysis of program code including various statistics of language constructs and analysis of Roles of Variables. In the second phase, the algorithms are classified based on these vectors using the C4.5 decision tree classifier. We have developed a prototype and successfully applied the method to sorting algorithms. Evaluated with leave-one-out technique, the accuracy of the constructed decision tree classifier is 97.1%.","1092-8138","978-1-4244-7603-9","10.1109/ICPC.2010.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5521763","Algorithm recognition;program comprehension;program understanding;roles of variables;C4.5 algorithm","Sorting;Decision trees;Classification tree analysis;Algorithm design and analysis;Statistical analysis;Computer science;Prototypes;Computational complexity;Computer languages;Programming profession","decision trees;pattern classification;sorting;statistical analysis","sorting algorithms;algorithm recognition;C4.5 decision tree classifier;language constructs statistics;program code analysis;roles-of-variables analysis;leave-one-out technique","","9","","23","IEEE","26 Jul 2010","","","IEEE","IEEE Conferences"
"Aiding Software Maintenance with Copy-and-Paste Clone-Awareness","P. Jablonski; D. Hou","School of Engineering, Clarkson University, Potsdam, NY, USA; School of Engineering, Clarkson University, Potsdam, NY, USA","2010 IEEE 18th International Conference on Program Comprehension","26 Jul 2010","2010","","","170","179","When programmers copy, paste, and then modify source code, the once-identical code fragments (code clones) can become indistinguishable as the software evolves over time. In this paper, we present three features of our software tool, a set of Eclipse plug-ins named CnP (CnP's clone visualization, CReN, and LexId), which aids the programmer during copy-and-paste programming. We believe that the clone-awareness that the tool provides can help programmers benefit from this clone information during debugging and modification tasks, develop software more efficiently, and prevent inconsistent identifier renaming within clones. We tested these hypotheses with a user study and present our results.","1092-8138","978-1-4244-7603-9","10.1109/ICPC.2010.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5521749","code clone;copy-and-paste programming;Eclipse integrated development environment;identifier renaming;Java","Software maintenance;Cloning;Programming profession;Software tools;Visualization;Software debugging;Testing;Performance evaluation;Velocity measurement;Java","program debugging;software maintenance;software tools","software maintenance;copy-and-paste clone-awareness;source code;once-identical code fragments;code clones;software tool;CnP clone visualization;CReN;Eclipse plug-ins;Lexld;debugging;clone information","","15","","28","IEEE","26 Jul 2010","","","IEEE","IEEE Conferences"
"Vivisection of a Non-Executable, Domain-Specific Language - Understanding (the Usage of) the P3P Language","R. Lämmel; E. Pek","Software Languages Team & ADAPT Lab, Universität Koblenz-Landau, Germany; Software Languages Team & ADAPT Lab, Universität Koblenz-Landau, Germany","2010 IEEE 18th International Conference on Program Comprehension","26 Jul 2010","2010","","","104","113","P3P is the policy language with which websites declare the intended use of data that is collected about users of the site. We have systematically collected P3P-based privacy policies from websites listed in the Google directory, and analysed the resulting corpus with regard to different levels of validity, size or complexity metrics, different cloning levels, coverage of language constructs, and the use of the language’s extension mechanism. In this manner, we have found interesting characteristics of P3P in the wild. For instance, cloning is exceptionally common in this domain, and encountered language extensions exceed the base language in terms of grammar complexity. Overall, this effort helps understanding the de-facto usage of the non-executable, domain-specific language P3P. Some elements of our methodology may be useful for other software languages as well.","1092-8138","978-1-4244-7603-9","10.1109/ICPC.2010.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5521756","empirical study;P3P;software language engineering;cloning;metrics;coverage","Domain specific languages;Privacy;Cloning;Vocabulary;Reverse engineering;Computer languages;Software engineering;Decision making;Navigation;Internet","data privacy;programming languages","domain-specific language;P3P language;P3P-based privacy policies;grammar complexity;software languages;privacy preferences project language","","3","","25","IEEE","26 Jul 2010","","","IEEE","IEEE Conferences"
"Identifying Dormant Functionality in Malware Programs","P. M. Comparetti; G. Salvaneschi; E. Kirda; C. Kolbitsch; C. Kruegel; S. Zanero","Technical University of of Vienna, Austria; Politecnico di Milano, Italy; Institut Eurecom, France; Technical University of of Vienna, Austria; University of California, Santa Barbara, USA; Politecnico di Milano, Italy","2010 IEEE Symposium on Security and Privacy","8 Jul 2010","2010","","","61","76","To handle the growing flood of malware, security vendors and analysts rely on tools that automatically identify and analyze malicious code. Current systems for automated malware analysis typically follow a dynamic approach, executing an unknown program in a controlled environment (sandbox) and recording its runtime behavior. Since dynamic analysis platforms directly run malicious code, they are resilient to popular malware defense techniques such as packing and code obfuscation. Unfortunately, in many cases, only a small subset of all possible malicious behaviors is observed within the short time frame that a malware sample is executed. To mitigate this issue, previous work introduced techniques such as multipath or forced execution to increase the coverage of dynamic malware analysis. Unfortunately, using these techniques is potentially expensive, as the number of paths that require analysis can grow exponentially. In this paper, we propose REANIMATOR, a novel solution to determine the capabilities (malicious functionality) of malware programs. Our solution is based on the insight that we can leverage behavior observed while dynamically executing a specific malware sample to identify similar functionality in other programs. More precisely, when we observe malicious actions during dynamic analysis, we automatically extract and model the parts of the malware binary that are responsible for this behavior. We then leverage these models to check whether similar code is present in other samples. This allows us to statically identify dormant functionality (functionality that is not observed during dynamic analysis) in malicious programs. We evaluate our approach on thousands of realworld malware samples, and we show that our system is successful in identifying additional, malicious functionality. As a result, our approach can significantly improve the coverage of malware analysis results.","2375-1207","978-1-4244-6895-9","10.1109/SP.2010.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5504706","malware analysis;dormant functionality;binary analysis","Computer architecture;Computational modeling;Registers;Assembly;Digital signal processing;Digital signal processing chips;Telecommunication control;Large scale integration;Logic;Educational institutions","data analysis;invasive software","dormant functionality identification;malware programs;malicious code;sandbox environment;packing technique;code obfuscation technique;malicious behaviors;dynamic malware analysis;multipath technique;forced execution technique;Reanimator solution","","61","2","39","IEEE","8 Jul 2010","","","IEEE","IEEE Conferences"
"An Extended Line-Based Approach to Detect Code Clones Using Syntactic and Lexical Information","K. Maeda","Department of Business Administration and Information Science, Chubu University, Kasugai, Aichi, Japan","2010 Seventh International Conference on Information Technology: New Generations","1 Jul 2010","2010","","","1237","1240","This paper proposes a new line-based approach for the detection of code clones using syntactic and lexical information. A customized compiler writes a source code representation that contains syntactic and lexical information. A new clone detection tool called LePalex reads the source code representation, and converts it to three types of code: first normal form, second normal form, and third normal form. The first normal form is used to detect the exact match of code clones. The second normal form is used to detect the syntactic match of code clones. The third normal form is used to check for syntactically correct segments of code clones. This paper demonstrates the advantage of this approach in achieving programming language independence using syntactic and lexical information.","","978-1-4244-6271-1","10.1109/ITNG.2010.176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5501550","Code Clone;Source Code Representation;String Matching","Cloning;Computer languages;Testing;Information technology;Information science;Computer bugs;Graphical user interfaces;Java;Libraries;Operating systems","application program interfaces;program compilers","extended line-based approach;code clone detection;syntactic information;lexical information;customized compiler;source code representation;LePalex;programming language independence;application program interfaces","","2","","10","IEEE","1 Jul 2010","","","IEEE","IEEE Conferences"
"High performance solid state storage under Linux","E. Seppanen; M. T. O'Keefe; D. J. Lilja","Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, USA; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, USA; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, USA","2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST)","28 Jun 2010","2010","","","1","12","Solid state drives (SSDs) allow single-drive performance that is far greater than disks can produce. Their low latency and potential for parallel operations mean that they are able to read and write data at speeds that strain operating system I/O interfaces. Additionally, their performance characteristics expose gaps in existing benchmarking methodologies. We discuss the impact on Linux system design of a prototype PCI Express SSD that operates at least an order of magnitude faster than most drives available today. We develop benchmarking strategies and focus on several areas where current Linux systems need improvement, and suggest methods of taking full advantage of such high-performance solid state storage. We demonstrate that an SSD can perform with high throughput, high operation rates, and low latency under the most difficult conditions. This suggests that high-performance SSDs can dramatically improve parallel I/O performance for future high performance computing (HPC) systems.","2160-1968","978-1-4244-7153-9","10.1109/MSST.2010.5496976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5496976","","Solid state circuits;Linux;Disk drives;Delay;Prototypes;Throughput;Capacitive sensors;Operating systems;High performance computing;Degradation","flash memories;Linux","solid state storage;Linux system;solid state drives;SSD;strain operating system;I/O interfaces;benchmarking methodologies;high performance computing;HPC","","15","26","18","IEEE","28 Jun 2010","","","IEEE","IEEE Conferences"
"A metric space based software clone detection approach","Z. O. Li; J. Sun","Computer Science College, University of Zhejiang, Hangzhou, China; Computer Science College, University of Zhejiang, Hangzhou, China","2010 2nd IEEE International Conference on Information Management and Engineering","3 Jun 2010","2010","","","393","397","Metric space is a set with definition of distance between elements within this set. This paper introduces metric space into code clone detection, and uses the distance within a metric space to measure the similarity level of code. It proposed a process of building up a metric space to detect clones in software system. Based on metric space which is derived from software metric, the clone detection can get more convenience and flexibility. We also exercise the approach in a real industry project.","","978-1-4244-5263-7","10.1109/ICIME.2010.5478099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5478099","metric space;clone detection;software metric;proximity query (key words)","Extraterrestrial measurements;Cloning;Software maintenance;Software systems;Computer science;Educational institutions;Software metrics;Robustness;Information analysis;Sun","software metrics","metric space;software clone detection approach;code clone detection","","2","","15","IEEE","3 Jun 2010","","","IEEE","IEEE Conferences"
"On the Use of Properties in Java Applications","M. Lumpe; S. Mahmud; R. Vasa","Faculty of Information and Communication Technologies, Swinburne University of Technology, Hawthorn, VIC, Australia; Faculty of Information and Communication Technologies, Swinburne University of Technology, Hawthorn, VIC, Australia; Faculty of Information and Communication Technologies, Swinburne University of Technology, Hawthorn, VIC, Australia","2010 21st Australian Software Engineering Conference","1 Jun 2010","2010","","","235","244","When building software systems, developers have to weigh the benefits of using one specific solution approach against the risks and costs of using another one. This process is not random. Certain preferences, architectural styles, and solution domain pressures create systematic biases that we can measure in order to assess their impact on the system being built and the underlying development process itself. In this paper we explore, whether the getter and setter methods in Java give rise to a bias also. Getter and setter methods, called ""properties"", are perceived commonplace and considered by some as a threat to data encapsulation. However, little empirical evidence exists that can reliably inform us about the real impact of the use of properties in Java. For this reason, we examined 102 open-source Java systems and discovered that properties are employed much more carefully than one might expect. Contrary to some folklore, developers use properties not just to gain access to an object's private state, but in a systematic and responsible manner and, in general, consistent with the domain requirements of the developed software system.","2377-5408","978-1-4244-6476-0","10.1109/ASWEC.2010.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5475032","empirical study;open-source software;Gini coefficient;decision framing","Java;Gettering;Data encapsulation;Open source software;Software systems;Australia;Mechanical factors;Software metrics;Software engineering;Application software","data encapsulation;Java;public domain software","Java applications;open-source software;data encapsulation","","7","","25","IEEE","1 Jun 2010","","","IEEE","IEEE Conferences"
"Random-walk based approach to detect clone attacks in wireless sensor networks","Y. Zeng; J. Cao; S. Zhang; S. Guo; L. Xie","State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, China; Department of Computing, Hong Kong Polytechnic University, Hong Kong, China; State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, China; School of Computer Science and Technology, Shandong University, Jinan, China; State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, China","IEEE Journal on Selected Areas in Communications","27 May 2010","2010","28","5","677","691","Wireless sensor networks (WSNs) deployed in hostile environments are vulnerable to clone attacks. In such attack, an adversary compromises a few nodes, replicates them, and inserts arbitrary number of replicas into the network. Consequently, the adversary can carry out many internal attacks. Previous solutions on detecting clone attacks have several drawbacks. First, some of them require a central control, which introduces several inherent limits. Second, some of them are deterministic and vulnerable to simple witness compromising attacks. Third, in some solutions the adversary can easily learn the critical witness nodes to start smart attacks and protect replicas from being detected. In this paper, we first show that in order to avoid existing drawbacks, replica-detection protocols must be non-deterministic and fully distributed (NDFD), and fulfill three security requirements on witness selection. To our knowledge, only one existing protocol, Randomized Multicast, is NDFD and fulfills the requirements, but it has very high communication overhead. Then, based on random walk, we propose two new NDFD protocols, RAndom WaLk (RAWL) and Table-assisted RAndom WaLk (TRAWL), which fulfill the requirements while having only moderate communication and memory overheads. The random walk strategy outperforms previous strategies because it distributes a core step, the witness selection, to every passed node of random walks, and then the adversary cannot easily find out the critical witness nodes. We theoretically analyze the required number of walk steps for ensuring detection. Our simulation results show that our protocols outperform an existing NDFD protocol with the lowest overheads in witness selection, and TRAWL even has lower memory overhead than that protocol. The communication overheads of our protocols are higher but are affordable considering their security benefits.","1558-0008","","10.1109/JSAC.2010.100606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5472424","Wireless sensor networks;computer network security;clone attacks;node replication,;random walk","Cloning;Wireless sensor networks;Multicast protocols;Application software;Centralized control;Protection;Computational modeling;Computer networks;Computer security;Military computing","multicast communication;protocols;telecommunication transmission lines;wireless sensor networks","wireless sensor networks;table-assisted random walk;clone attack detection;hostile environments;arbitrary number;internal attacks;critical witness nodes;replica-detection protocols;randomized multicast;communication overhead;NDFD protocols","","76","","38","IEEE","27 May 2010","","","IEEE","IEEE Journals"
"An efficient GPU implementation of the revised simplex method","J. Bieling; P. Peschlow; P. Martini","Institute of Computer Science, University of Bonn, Bonn, Germany; Institute of Computer Science, University of Bonn, Bonn, Germany; Institute of Computer Science, University of Bonn, Bonn, Germany","2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)","24 May 2010","2010","","","1","8","The computational power provided by the massive parallelism of modern graphics processing units (GPUs) has moved increasingly into focus over the past few years. In particular, general purpose computing on GPUs (GPGPU) is attracting attention among researchers and practitioners alike. Yet GPGPU research is still in its infancy, and a major challenge is to rearrange existing algorithms so as to obtain a significant performance gain from the execution on a GPU. In this paper, we address this challenge by presenting an efficient GPU implementation of a very popular algorithm for linear programming, the revised simplex method. We describe how to carry out the steps of the revised simplex method to take full advantage of the parallel processing capabilities of a GPU. Our experiments demonstrate considerable speedup over a widely used CPU implementation, thus underlining the tremendous potential of GPGPU.","","978-1-4244-6534-7","10.1109/IPDPSW.2010.5470831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5470831","","Linear programming;Parallel processing;Scalability;Hardware;Linear algebra;Computer science;Concurrent computing;Computer graphics;Performance gain;Central Processing Unit","coprocessors;linear programming;mathematics computing;parallel processing","revised simplex method;graphics processing units;general purpose computing;linear programming;parallel processing","","18","1","21","IEEE","24 May 2010","","","IEEE","IEEE Conferences"
